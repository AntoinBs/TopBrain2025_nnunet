{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dedabf2c",
      "metadata": {
        "id": "dedabf2c",
        "outputId": "219e7c8c-7669-4e81-da07-425b8cf5959b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ GPU détecté : NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "\n",
        "# 1. Monter Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Vérifier que le GPU est bien actif\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✅ GPU détecté : {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"❌ Pas de GPU détecté. Allez dans Exécution > Modifier le type d'exécution > T4 GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install monai"
      ],
      "metadata": {
        "id": "0TUq8qSgteAr",
        "outputId": "c6a04c01-adef-46c2-f6f6-b2fec0d44684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "0TUq8qSgteAr",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Collecting torch==2.8.0\n",
            "  Downloading https://download.pytorch.org/whl/cu126/torch-2.8.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision==0.23.0\n",
            "  Downloading https://download.pytorch.org/whl/cu126/torchvision-0.23.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio==2.8.0\n",
            "  Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.8.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (1.11.1.6)\n",
            "Collecting triton==3.4.0 (from torch==2.8.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0) (3.0.3)\n",
            "Downloading https://download.pytorch.org/whl/cu126/torch-2.8.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl (821.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.8/821.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchvision-0.23.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m155.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchaudio-2.8.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.9.0+cu126\n",
            "    Uninstalling torchaudio-2.9.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Successfully installed nvidia-nccl-cu12-2.27.3 torch-2.8.0+cu126 torchaudio-2.8.0+cu126 torchvision-0.23.0+cu126 triton-3.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "76a34ae0ba89460e98547403552b5e43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.12/dist-packages (from monai) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from monai) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.3)\n",
            "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AntoinBs/nnUNet.git\n",
        "!cd nnUNet && pip install -e . && pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git"
      ],
      "metadata": {
        "id": "G8O7ue9nuDBH",
        "outputId": "e3d89d5a-7504-40a6-c95a-d01c459236c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "G8O7ue9nuDBH",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nnUNet'...\n",
            "remote: Enumerating objects: 14026, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14026 (delta 8), reused 16 (delta 7), pack-reused 14006 (from 2)\u001b[K\n",
            "Receiving objects: 100% (14026/14026), 8.62 MiB | 18.61 MiB/s, done.\n",
            "Resolving deltas: 100% (10700/10700), done.\n",
            "Obtaining file:///content/nnUNet\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (2.8.0+cu126)\n",
            "Collecting acvl-utils<0.3,>=0.2.3 (from nnunetv2==2.6.2)\n",
            "  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dynamic-network-architectures<0.5,>=0.4.1 (from nnunetv2==2.6.2)\n",
            "  Downloading dynamic_network_architectures-0.4.2.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (1.16.3)\n",
            "Collecting batchgenerators>=0.25.1 (from nnunetv2==2.6.2)\n",
            "  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (0.25.2)\n",
            "Collecting SimpleITK>=2.2.1 (from nnunetv2==2.6.2)\n",
            "  Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (0.21)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (2025.10.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (2.32.4)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (0.13.2)\n",
            "Collecting imagecodecs (from nnunetv2==2.6.2)\n",
            "  Downloading imagecodecs-2025.11.11-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (20 kB)\n",
            "Collecting yacs (from nnunetv2==2.6.2)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting batchgeneratorsv2>=0.3.0 (from nnunetv2==2.6.2)\n",
            "  Downloading batchgeneratorsv2-0.3.0.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (0.8.1)\n",
            "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.12/dist-packages (from nnunetv2==2.6.2) (3.11.1)\n",
            "Collecting connected-components-3d (from acvl-utils<0.3,>=0.2.3->nnunetv2==2.6.2)\n",
            "  Downloading connected_components_3d-3.26.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (11.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.0.0)\n",
            "Collecting unittest2 (from batchgenerators>=0.25.1->nnunetv2==2.6.2)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.12/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (3.6.0)\n",
            "Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.3.0->nnunetv2==2.6.2)\n",
            "  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.12/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (1.10.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (1.1.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (4.5.0)\n",
            "Requirement already satisfied: numexpr>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (2.14.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (9.0.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.0.22)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (3.6)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (2.37.2)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nnunetv2==2.6.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nnunetv2==2.6.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nnunetv2==2.6.2) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nnunetv2==2.6.2) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nnunetv2==2.6.2) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nnunetv2==2.6.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->nnunetv2==2.6.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->nnunetv2==2.6.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->nnunetv2==2.6.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->nnunetv2==2.6.2) (2025.11.12)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->nnunetv2==2.6.2) (1.5.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from yacs->nnunetv2==2.6.2) (6.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.6.2) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.2->nnunetv2==2.6.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.2->nnunetv2==2.6.2) (3.0.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.23.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.7.0)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting traceback2 (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.2.0)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n",
            "Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2025.11.11-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading connected_components_3d-3.26.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n",
            "  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.6.2-0.editable-py3-none-any.whl size=16837 sha256=ac4c0d57a1dd49d0fb75f7b611cdcf5bd7f6703ee3d2051d9796c062d98ec247\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zbtu1s7d/wheels/e4/49/54/747a776959ad4bad6675565e9c9011de0787353cf8a2e4683d\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27213 sha256=a70b35baffba8e3c5c7ff0dcb6e8141b1da49a6f0b02aea062081940254d16c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/c4/16/bae888b32a033f634d91a14256a8f8c8ec97db4e4dad8f0216\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=65a60dc93fcf26c8140b9d2afa9a088c0d8d312047fddaec4fd014864b58a75f\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/21/2b/7b25080f9f5847e6c3162b89d859d7cec9f3093158e56bd008\n",
            "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.3.0-py3-none-any.whl size=65215 sha256=dacf6370fa37e8c20c789aaa9e3092babb63eb3c730562e63ba28c5c1c7d581f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/99/a0/1224a58f286be9fedbdb256d41e782a63b5ecab743e92ed302\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.4.2-py3-none-any.whl size=39025 sha256=eaa4edd967dab9734eec4da7eee6e0d5b9cb1b063aedf3ce36248c55c59332c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/a8/c5/241ab34db40b3a6f498d2794411cc08a6309fefdc0d6e3d9f3\n",
            "Successfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\n",
            "Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, imagecodecs, connected-components-3d, unittest2, batchgenerators, fft-conv-pytorch, acvl-utils, batchgeneratorsv2, dynamic-network-architectures, nnunetv2\n",
            "Successfully installed SimpleITK-2.5.3 acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.3.0 connected-components-3d-3.26.1 dynamic-network-architectures-0.4.2 fft-conv-pytorch-1.2.0 imagecodecs-2025.11.11 linecache2-1.0.0 nnunetv2-2.6.2 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n",
            "Collecting git+https://github.com/FabianIsensee/hiddenlayer.git\n",
            "  Cloning https://github.com/FabianIsensee/hiddenlayer.git to /tmp/pip-req-build-555xa_rf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FabianIsensee/hiddenlayer.git /tmp/pip-req-build-555xa_rf\n",
            "  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit b7263b6dc4569da1b6dea5964e1eac78fa32fa77\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hiddenlayer\n",
            "  Building wheel for hiddenlayer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hiddenlayer: filename=hiddenlayer-0.2-py3-none-any.whl size=20004 sha256=2b07a00e01b6f9b467ec69c5cb178cfc01ed350baecd5608eb20b8d06b025c01\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zrrvvjtz/wheels/87/95/c2/988265e8d5046e61a213ee5000db03954c7a5eaa7febcf82a3\n",
            "Successfully built hiddenlayer\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "422d73ec",
      "metadata": {
        "id": "422d73ec",
        "outputId": "190013d4-ca43-4069-b920-9088e11cabb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dossier preprocessed trouvé : /content/drive/MyDrive/Projets_perso/Projet_IA/TopBrain2025_nnunet/nnunet_data/nnUNet_preprocessed\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# --- VOTRE CONFIGURATION ---\n",
        "# Chemin vers le dossier contenant 'nnunet_data'\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/Projets_perso/Projet_IA/TopBrain2025_nnunet\"\n",
        "# ---------------------------\n",
        "\n",
        "# Définition des variables d'environnement\n",
        "os.environ['nnUNet_raw'] = os.path.join(PROJECT_DIR, 'nnunet_data/nnUNet_raw')\n",
        "os.environ['nnUNet_preprocessed'] = os.path.join(PROJECT_DIR, 'nnunet_data/nnUNet_preprocessed')\n",
        "os.environ['nnUNet_results'] = os.path.join(PROJECT_DIR, 'nnunet_data/nnUNet_results')\n",
        "\n",
        "# Vérification que les dossiers existent (pour éviter les erreurs bêtes)\n",
        "if os.path.exists(os.environ['nnUNet_preprocessed']):\n",
        "    print(f\"✅ Dossier preprocessed trouvé : {os.environ['nnUNet_preprocessed']}\")\n",
        "else:\n",
        "    print(f\"❌ Attention : Le dossier preprocessed semble introuvable à cet endroit.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cf0c2ada",
      "metadata": {
        "id": "cf0c2ada",
        "outputId": "e100d7f1-9cb9-4857-fb86-9ae7e32a9e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n",
            "2025-12-03 15:04:57.881666: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 15:04:57.898693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764774297.919480    3106 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764774297.925832    3106 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764774297.941424    3106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764774297.941452    3106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764774297.941455    3106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764774297.941457    3106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 15:04:57.946239: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2025-12-03 15:05:05.183397: Using torch.compile...\n",
            "2025-12-03 15:05:07.291847: Using Dice + CE + clDice Loss for training.\n",
            "################### Loading pretrained weights from file  /content/drive/MyDrive/Projets_perso/Projet_IA/TopBrain2025_nnunet/nnunet_data/nnUNet_results/Dataset100_CTA_AND_MRA_pretraining/nnUNetTrainerDiceCEClDiceLoss__nnUNetPlans_From_000__3d_fullres/fold_all/checkpoint_best.pth ###################\n",
            "Below is the list of overlapping blocks in pretrained model and nnUNet architecture:\n",
            "encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])\n",
            "encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])\n",
            "encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
            "encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
            "encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])\n",
            "encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])\n",
            "encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])\n",
            "encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])\n",
            "encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
            "encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
            "encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])\n",
            "encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])\n",
            "encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])\n",
            "encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])\n",
            "encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
            "encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
            "encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])\n",
            "encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])\n",
            "encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])\n",
            "encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])\n",
            "encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
            "encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
            "encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])\n",
            "encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])\n",
            "encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])\n",
            "encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])\n",
            "encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])\n",
            "encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])\n",
            "encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])\n",
            "decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])\n",
            "decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
            "decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
            "decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])\n",
            "decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])\n",
            "decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])\n",
            "decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])\n",
            "decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
            "decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
            "decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])\n",
            "decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])\n",
            "decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])\n",
            "decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])\n",
            "decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
            "decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
            "decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])\n",
            "decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])\n",
            "decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])\n",
            "decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])\n",
            "decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
            "decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
            "decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])\n",
            "decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])\n",
            "decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])\n",
            "decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])\n",
            "decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])\n",
            "decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])\n",
            "decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])\n",
            "decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])\n",
            "decoder.stages.0.convs.0.conv.bias shape torch.Size([320])\n",
            "decoder.stages.0.convs.0.norm.weight shape torch.Size([320])\n",
            "decoder.stages.0.convs.0.norm.bias shape torch.Size([320])\n",
            "decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])\n",
            "decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])\n",
            "decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])\n",
            "decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])\n",
            "decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "decoder.stages.0.convs.1.conv.bias shape torch.Size([320])\n",
            "decoder.stages.0.convs.1.norm.weight shape torch.Size([320])\n",
            "decoder.stages.0.convs.1.norm.bias shape torch.Size([320])\n",
            "decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
            "decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])\n",
            "decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])\n",
            "decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])\n",
            "decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])\n",
            "decoder.stages.1.convs.0.conv.bias shape torch.Size([256])\n",
            "decoder.stages.1.convs.0.norm.weight shape torch.Size([256])\n",
            "decoder.stages.1.convs.0.norm.bias shape torch.Size([256])\n",
            "decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])\n",
            "decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])\n",
            "decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])\n",
            "decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])\n",
            "decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
            "decoder.stages.1.convs.1.conv.bias shape torch.Size([256])\n",
            "decoder.stages.1.convs.1.norm.weight shape torch.Size([256])\n",
            "decoder.stages.1.convs.1.norm.bias shape torch.Size([256])\n",
            "decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
            "decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])\n",
            "decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])\n",
            "decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])\n",
            "decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])\n",
            "decoder.stages.2.convs.0.conv.bias shape torch.Size([128])\n",
            "decoder.stages.2.convs.0.norm.weight shape torch.Size([128])\n",
            "decoder.stages.2.convs.0.norm.bias shape torch.Size([128])\n",
            "decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])\n",
            "decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])\n",
            "decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])\n",
            "decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])\n",
            "decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
            "decoder.stages.2.convs.1.conv.bias shape torch.Size([128])\n",
            "decoder.stages.2.convs.1.norm.weight shape torch.Size([128])\n",
            "decoder.stages.2.convs.1.norm.bias shape torch.Size([128])\n",
            "decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
            "decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])\n",
            "decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])\n",
            "decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])\n",
            "decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])\n",
            "decoder.stages.3.convs.0.conv.bias shape torch.Size([64])\n",
            "decoder.stages.3.convs.0.norm.weight shape torch.Size([64])\n",
            "decoder.stages.3.convs.0.norm.bias shape torch.Size([64])\n",
            "decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])\n",
            "decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])\n",
            "decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])\n",
            "decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])\n",
            "decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
            "decoder.stages.3.convs.1.conv.bias shape torch.Size([64])\n",
            "decoder.stages.3.convs.1.norm.weight shape torch.Size([64])\n",
            "decoder.stages.3.convs.1.norm.bias shape torch.Size([64])\n",
            "decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
            "decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])\n",
            "decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])\n",
            "decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])\n",
            "decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])\n",
            "decoder.stages.4.convs.0.conv.bias shape torch.Size([32])\n",
            "decoder.stages.4.convs.0.norm.weight shape torch.Size([32])\n",
            "decoder.stages.4.convs.0.norm.bias shape torch.Size([32])\n",
            "decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])\n",
            "decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])\n",
            "decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])\n",
            "decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])\n",
            "decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
            "decoder.stages.4.convs.1.conv.bias shape torch.Size([32])\n",
            "decoder.stages.4.convs.1.norm.weight shape torch.Size([32])\n",
            "decoder.stages.4.convs.1.norm.bias shape torch.Size([32])\n",
            "decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
            "decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])\n",
            "decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])\n",
            "decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])\n",
            "decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])\n",
            "decoder.transpconvs.0.bias shape torch.Size([320])\n",
            "decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])\n",
            "decoder.transpconvs.1.bias shape torch.Size([256])\n",
            "decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])\n",
            "decoder.transpconvs.2.bias shape torch.Size([128])\n",
            "decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])\n",
            "decoder.transpconvs.3.bias shape torch.Size([64])\n",
            "decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])\n",
            "decoder.transpconvs.4.bias shape torch.Size([32])\n",
            "################### Done ###################\n",
            "2025-12-03 15:05:20.156628: do_dummy_2d_data_aug: False\n",
            "2025-12-03 15:05:20.161936: Using splits from existing split file: /content/drive/MyDrive/Projets_perso/Projet_IA/TopBrain2025_nnunet/nnunet_data/nnUNet_preprocessed/Dataset000_CTA_AND_MRA/splits_final.json\n",
            "2025-12-03 15:05:20.781462: The split file contains 5 splits.\n",
            "2025-12-03 15:05:20.784343: Desired fold for training: 0\n",
            "2025-12-03 15:05:20.786994: This split has 30 training and 8 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 128], 'median_image_size_in_voxels': [213.5, 452.5, 372.0], 'spacing': [0.6000011265277863, 0.375, 0.375], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset000_CTA_AND_MRA', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.6000011265277863, 0.375, 0.375], 'original_median_shape_after_transp': [194, 470, 390], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1463.0771484375, 'mean': 219.11074829101562, 'median': 180.50819396972656, 'min': -22.987985610961914, 'percentile_00_5': 68.67970802307129, 'percentile_99_5': 748.2167355346719, 'std': 128.34088134765625}}} \n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "2025-12-03 15:05:56.658258: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2025-12-03 15:05:56.696541: \n",
            "2025-12-03 15:05:56.699786: Epoch 0\n",
            "2025-12-03 15:05:56.703919: Current learning rate: 0.01\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "W1203 15:06:09.657000 3106 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "2025-12-03 15:09:47.803355: train_loss 1.5032\n",
            "2025-12-03 15:09:47.807001: val_loss 1.1694\n",
            "2025-12-03 15:09:47.810887: Pseudo dice [np.float32(0.0), np.float32(0.0), np.float32(0.0204), np.float32(0.29), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:09:47.813470: Epoch time: 231.11 s\n",
            "2025-12-03 15:09:47.816435: Yayy! New best EMA pseudo Dice: 0.006500000134110451\n",
            "2025-12-03 15:09:49.445720: \n",
            "2025-12-03 15:09:49.448725: Epoch 1\n",
            "2025-12-03 15:09:49.452163: Current learning rate: 0.00999\n",
            "2025-12-03 15:12:22.699485: train_loss 1.1568\n",
            "2025-12-03 15:12:22.702972: val_loss 1.1608\n",
            "2025-12-03 15:12:22.706697: Pseudo dice [np.float32(0.0378), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2677), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:12:22.709391: Epoch time: 153.26 s\n",
            "2025-12-03 15:12:24.024573: \n",
            "2025-12-03 15:12:24.027639: Epoch 2\n",
            "2025-12-03 15:12:24.030867: Current learning rate: 0.00998\n",
            "2025-12-03 15:15:05.507352: train_loss 1.1428\n",
            "2025-12-03 15:15:05.510931: val_loss 1.1438\n",
            "2025-12-03 15:15:05.514611: Pseudo dice [np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2692), np.float32(0.0), np.float32(0.0135), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:15:05.517480: Epoch time: 161.48 s\n",
            "2025-12-03 15:15:06.904975: \n",
            "2025-12-03 15:15:06.907889: Epoch 3\n",
            "2025-12-03 15:15:06.910889: Current learning rate: 0.00997\n",
            "2025-12-03 15:17:47.729602: train_loss 1.1417\n",
            "2025-12-03 15:17:47.732945: val_loss 1.1289\n",
            "2025-12-03 15:17:47.736155: Pseudo dice [np.float32(0.0006), np.float32(0.0), np.float32(0.0), np.float32(0.2758), np.float32(0.0), np.float32(0.0002), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:17:47.738674: Epoch time: 160.83 s\n",
            "2025-12-03 15:17:49.082925: \n",
            "2025-12-03 15:17:49.085637: Epoch 4\n",
            "2025-12-03 15:17:49.088520: Current learning rate: 0.00996\n",
            "2025-12-03 15:20:32.980034: train_loss 1.1311\n",
            "2025-12-03 15:20:32.985479: val_loss 1.1284\n",
            "2025-12-03 15:20:32.989877: Pseudo dice [np.float32(0.0045), np.float32(0.0), np.float32(0.0), np.float32(1e-04), np.float32(0.0), np.float32(0.2943), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:20:32.992856: Epoch time: 163.9 s\n",
            "2025-12-03 15:20:34.401304: \n",
            "2025-12-03 15:20:34.404656: Epoch 5\n",
            "2025-12-03 15:20:34.408256: Current learning rate: 0.00995\n",
            "2025-12-03 15:23:07.765215: train_loss 1.1228\n",
            "2025-12-03 15:23:07.768610: val_loss 1.1279\n",
            "2025-12-03 15:23:07.771837: Pseudo dice [np.float32(0.0105), np.float32(0.0), np.float32(0.0), np.float32(0.0009), np.float32(0.0), np.float32(0.3279), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:23:07.774521: Epoch time: 153.37 s\n",
            "2025-12-03 15:23:09.104065: \n",
            "2025-12-03 15:23:09.106769: Epoch 6\n",
            "2025-12-03 15:23:09.109895: Current learning rate: 0.00995\n",
            "/content/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1114: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  global_dc_per_class = [i for i in [2 * i / (2 * i + j + k) for i, j, k in zip(tp, fp, fn)]]\n",
            "2025-12-03 15:25:42.525643: train_loss 1.1248\n",
            "2025-12-03 15:25:42.529454: val_loss 1.1235\n",
            "2025-12-03 15:25:42.533336: Pseudo dice [np.float32(0.0066), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2394), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:25:42.536387: Epoch time: 153.42 s\n",
            "2025-12-03 15:25:44.774046: \n",
            "2025-12-03 15:25:44.777035: Epoch 7\n",
            "2025-12-03 15:25:44.780847: Current learning rate: 0.00994\n",
            "2025-12-03 15:28:18.298585: train_loss 1.1237\n",
            "2025-12-03 15:28:18.302110: val_loss 1.1197\n",
            "2025-12-03 15:28:18.306246: Pseudo dice [np.float32(0.0354), np.float32(0.0), np.float32(0.0), np.float32(0.0064), np.float32(0.0), np.float32(0.2992), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:28:18.308797: Epoch time: 153.53 s\n",
            "2025-12-03 15:28:19.658767: \n",
            "2025-12-03 15:28:19.661587: Epoch 8\n",
            "2025-12-03 15:28:19.664493: Current learning rate: 0.00993\n",
            "2025-12-03 15:30:53.290966: train_loss 1.115\n",
            "2025-12-03 15:30:53.294288: val_loss 1.1126\n",
            "2025-12-03 15:30:53.297741: Pseudo dice [np.float32(0.0799), np.float32(0.0), np.float32(0.0), np.float32(0.2991), np.float32(0.0), np.float32(0.1907), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:30:53.300393: Epoch time: 153.63 s\n",
            "2025-12-03 15:30:53.303254: Yayy! New best EMA pseudo Dice: 0.006899999920278788\n",
            "2025-12-03 15:30:55.248976: \n",
            "2025-12-03 15:30:55.251879: Epoch 9\n",
            "2025-12-03 15:30:55.255585: Current learning rate: 0.00992\n",
            "2025-12-03 15:33:30.635879: train_loss 1.1168\n",
            "2025-12-03 15:33:30.639825: val_loss 1.1191\n",
            "2025-12-03 15:33:30.643818: Pseudo dice [np.float32(0.0536), np.float32(0.0), np.float32(0.0), np.float32(0.3584), np.float32(0.0), np.float32(0.0212), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:33:30.646875: Epoch time: 155.39 s\n",
            "2025-12-03 15:33:30.650186: Yayy! New best EMA pseudo Dice: 0.0071000000461936\n",
            "2025-12-03 15:33:32.575359: \n",
            "2025-12-03 15:33:32.578809: Epoch 10\n",
            "2025-12-03 15:33:32.583681: Current learning rate: 0.00991\n",
            "2025-12-03 15:36:06.396134: train_loss 1.1135\n",
            "2025-12-03 15:36:06.400108: val_loss 1.1124\n",
            "2025-12-03 15:36:06.405012: Pseudo dice [np.float32(0.1171), np.float32(0.0), np.float32(0.0), np.float32(0.3313), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:36:06.408324: Epoch time: 153.82 s\n",
            "2025-12-03 15:36:06.411877: Yayy! New best EMA pseudo Dice: 0.007400000002235174\n",
            "2025-12-03 15:36:08.437027: \n",
            "2025-12-03 15:36:08.440198: Epoch 11\n",
            "2025-12-03 15:36:08.443751: Current learning rate: 0.0099\n",
            "2025-12-03 15:38:47.013771: train_loss 1.1116\n",
            "2025-12-03 15:38:47.017801: val_loss 1.107\n",
            "2025-12-03 15:38:47.022024: Pseudo dice [np.float32(0.1208), np.float32(0.0), np.float32(0.0), np.float32(0.1473), np.float32(0.0), np.float32(0.3184), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0008), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:38:47.038715: Epoch time: 158.58 s\n",
            "2025-12-03 15:38:47.042565: Yayy! New best EMA pseudo Dice: 0.007899999618530273\n",
            "2025-12-03 15:38:49.114256: \n",
            "2025-12-03 15:38:49.117479: Epoch 12\n",
            "2025-12-03 15:38:49.121166: Current learning rate: 0.00989\n",
            "2025-12-03 15:41:25.404196: train_loss 1.1073\n",
            "2025-12-03 15:41:25.407449: val_loss 1.1096\n",
            "2025-12-03 15:41:25.411294: Pseudo dice [np.float32(0.1866), np.float32(1e-04), np.float32(0.0), np.float32(0.3851), np.float32(0.0), np.float32(0.001), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(nan), np.float32(0.0337), np.float32(0.0), np.float32(0.0002), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0006), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:41:25.414013: Epoch time: 156.29 s\n",
            "2025-12-03 15:41:25.417208: Yayy! New best EMA pseudo Dice: 0.00839999970048666\n",
            "2025-12-03 15:41:27.972051: \n",
            "2025-12-03 15:41:27.974955: Epoch 13\n",
            "2025-12-03 15:41:27.978015: Current learning rate: 0.00988\n",
            "2025-12-03 15:44:02.759792: train_loss 1.1063\n",
            "2025-12-03 15:44:02.762903: val_loss 1.1028\n",
            "2025-12-03 15:44:02.766175: Pseudo dice [np.float32(0.1944), np.float32(0.0118), np.float32(0.0), np.float32(0.0542), np.float32(0.0), np.float32(0.2772), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0202), np.float32(0.0), np.float32(0.0005), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:44:02.782192: Epoch time: 154.79 s\n",
            "2025-12-03 15:44:02.785317: Yayy! New best EMA pseudo Dice: 0.008700000122189522\n",
            "2025-12-03 15:44:04.732421: \n",
            "2025-12-03 15:44:04.735210: Epoch 14\n",
            "2025-12-03 15:44:04.738087: Current learning rate: 0.00987\n",
            "2025-12-03 15:46:45.357878: train_loss 1.0985\n",
            "2025-12-03 15:46:45.363087: val_loss 1.1095\n",
            "2025-12-03 15:46:45.368814: Pseudo dice [np.float32(0.1847), np.float32(0.0502), np.float32(0.0004), np.float32(0.4409), np.float32(0.0), np.float32(0.0555), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0847), np.float32(0.0), np.float32(0.0355), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:46:45.374050: Epoch time: 160.63 s\n",
            "2025-12-03 15:46:45.378172: Yayy! New best EMA pseudo Dice: 0.009600000455975533\n",
            "2025-12-03 15:46:47.592272: \n",
            "2025-12-03 15:46:47.763628: Epoch 15\n",
            "2025-12-03 15:46:47.767880: Current learning rate: 0.00986\n",
            "2025-12-03 15:49:24.463281: train_loss 1.1017\n",
            "2025-12-03 15:49:24.467121: val_loss 1.0939\n",
            "2025-12-03 15:49:24.469912: Pseudo dice [np.float32(0.2757), np.float32(0.1239), np.float32(0.0004), np.float32(0.4379), np.float32(0.0), np.float32(0.0545), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0947), np.float32(0.0), np.float32(0.0184), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:49:24.484159: Epoch time: 156.87 s\n",
            "2025-12-03 15:49:24.486538: Yayy! New best EMA pseudo Dice: 0.01080000028014183\n",
            "2025-12-03 15:49:26.472317: \n",
            "2025-12-03 15:49:26.476044: Epoch 16\n",
            "2025-12-03 15:49:26.478752: Current learning rate: 0.00986\n",
            "2025-12-03 15:52:03.243587: train_loss 1.1057\n",
            "2025-12-03 15:52:03.248925: val_loss 1.0948\n",
            "2025-12-03 15:52:03.253661: Pseudo dice [np.float32(0.2892), np.float32(0.0703), np.float32(0.0), np.float32(0.0438), np.float32(0.0), np.float32(0.4078), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0026), np.float32(0.0), np.float32(0.0003), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:52:03.256970: Epoch time: 156.77 s\n",
            "2025-12-03 15:52:03.261164: Yayy! New best EMA pseudo Dice: 0.01140000019222498\n",
            "2025-12-03 15:52:05.473191: \n",
            "2025-12-03 15:52:05.477131: Epoch 17\n",
            "2025-12-03 15:52:05.719298: Current learning rate: 0.00985\n",
            "2025-12-03 15:54:40.855940: train_loss 1.0954\n",
            "2025-12-03 15:54:40.859451: val_loss 1.0945\n",
            "2025-12-03 15:54:40.862838: Pseudo dice [np.float32(0.476), np.float32(0.1854), np.float32(0.0006), np.float32(0.573), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0199), np.float32(0.0), np.float32(0.0483), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:54:40.865417: Epoch time: 155.38 s\n",
            "2025-12-03 15:54:40.868421: Yayy! New best EMA pseudo Dice: 0.013000000268220901\n",
            "2025-12-03 15:54:42.772439: \n",
            "2025-12-03 15:54:42.775315: Epoch 18\n",
            "2025-12-03 15:54:42.778227: Current learning rate: 0.00984\n",
            "2025-12-03 15:57:25.200399: train_loss 1.0927\n",
            "2025-12-03 15:57:25.203900: val_loss 1.0943\n",
            "2025-12-03 15:57:25.207495: Pseudo dice [np.float32(0.2682), np.float32(0.101), np.float32(0.006), np.float32(1e-04), np.float32(0.0), np.float32(0.512), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0783), np.float32(0.0), np.float32(0.0492), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 15:57:25.223353: Epoch time: 162.43 s\n",
            "2025-12-03 15:57:25.226666: Yayy! New best EMA pseudo Dice: 0.013799999840557575\n",
            "2025-12-03 15:57:27.180891: \n",
            "2025-12-03 15:57:27.184049: Epoch 19\n",
            "2025-12-03 15:57:27.187277: Current learning rate: 0.00983\n",
            "2025-12-03 16:00:01.063155: train_loss 1.0962\n",
            "2025-12-03 16:00:01.067002: val_loss 1.0884\n",
            "2025-12-03 16:00:01.070492: Pseudo dice [np.float32(0.3759), np.float32(0.1267), np.float32(0.0085), np.float32(0.5473), np.float32(0.0), np.float32(0.0638), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0036), np.float32(0.0), np.float32(0.0096), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 16:00:01.073528: Epoch time: 153.88 s\n",
            "2025-12-03 16:00:01.076275: Yayy! New best EMA pseudo Dice: 0.014800000004470348\n",
            "2025-12-03 16:00:03.070328: \n",
            "2025-12-03 16:00:03.073045: Epoch 20\n",
            "2025-12-03 16:00:03.076042: Current learning rate: 0.00982\n",
            "2025-12-03 16:02:45.950996: train_loss 1.0879\n",
            "2025-12-03 16:02:45.955860: val_loss 1.0956\n",
            "2025-12-03 16:02:45.959989: Pseudo dice [np.float32(0.4915), np.float32(0.146), np.float32(0.0082), np.float32(0.4906), np.float32(0.0), np.float32(0.2324), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0013), np.float32(0.0), np.float32(0.0712), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0002), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 16:02:45.964490: Epoch time: 162.88 s\n",
            "2025-12-03 16:02:45.969048: Yayy! New best EMA pseudo Dice: 0.01640000008046627\n",
            "2025-12-03 16:02:48.130838: \n",
            "2025-12-03 16:02:48.134141: Epoch 21\n",
            "2025-12-03 16:02:48.137639: Current learning rate: 0.00981\n",
            "2025-12-03 16:05:23.808939: train_loss 1.0838\n",
            "2025-12-03 16:05:23.812613: val_loss 1.0841\n",
            "2025-12-03 16:05:23.815813: Pseudo dice [np.float32(0.5099), np.float32(0.1506), np.float32(0.0104), np.float32(0.1024), np.float32(0.0), np.float32(0.5637), np.float32(0.0002), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0005), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0055), np.float32(0.0), np.float32(0.0822), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(1e-04), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 16:05:23.829316: Epoch time: 155.68 s\n",
            "2025-12-03 16:05:23.832905: Yayy! New best EMA pseudo Dice: 0.01769999973475933\n",
            "2025-12-03 16:05:25.732390: \n",
            "2025-12-03 16:05:25.735303: Epoch 22\n",
            "2025-12-03 16:05:25.738576: Current learning rate: 0.0098\n",
            "2025-12-03 16:07:59.340093: train_loss 1.0828\n",
            "2025-12-03 16:07:59.343729: val_loss 1.0871\n",
            "2025-12-03 16:07:59.347497: Pseudo dice [np.float32(0.5019), np.float32(0.1725), np.float32(0.0563), np.float32(0.2762), np.float32(0.0), np.float32(0.4666), np.float32(0.0005), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0012), np.float32(1e-04), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0027), np.float32(0.0), np.float32(0.0176), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0005), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 16:07:59.350440: Epoch time: 153.61 s\n",
            "2025-12-03 16:07:59.353723: Yayy! New best EMA pseudo Dice: 0.01899999938905239\n",
            "2025-12-03 16:08:01.306305: \n",
            "2025-12-03 16:08:01.309281: Epoch 23\n",
            "2025-12-03 16:08:01.312229: Current learning rate: 0.00979\n",
            "2025-12-03 16:10:34.663921: train_loss 1.0863\n",
            "2025-12-03 16:10:34.667392: val_loss 1.0816\n",
            "2025-12-03 16:10:34.670980: Pseudo dice [np.float32(0.5641), np.float32(0.1494), np.float32(0.0552), np.float32(0.4532), np.float32(0.0002), np.float32(0.3277), np.float32(0.0009), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0007), np.float32(0.0), np.float32(0.0059), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0005), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 16:10:34.673701: Epoch time: 153.36 s\n",
            "2025-12-03 16:10:34.677167: Yayy! New best EMA pseudo Dice: 0.020400000736117363\n",
            "2025-12-03 16:10:36.632622: \n",
            "2025-12-03 16:10:36.635618: Epoch 24\n",
            "2025-12-03 16:10:36.639084: Current learning rate: 0.00978\n",
            "2025-12-03 16:13:17.950751: train_loss 1.0871\n",
            "2025-12-03 16:13:17.956223: val_loss 1.084\n",
            "2025-12-03 16:13:17.959487: Pseudo dice [np.float32(0.5512), np.float32(0.1619), np.float32(0.0551), np.float32(0.2289), np.float32(0.0083), np.float32(0.5756), np.float32(0.063), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0002), np.float32(0.0), np.float32(0.0149), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0312), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 16:13:17.974406: Epoch time: 161.32 s\n",
            "2025-12-03 16:13:17.977462: Yayy! New best EMA pseudo Dice: 0.021900000050663948\n",
            "2025-12-03 16:13:20.517130: \n",
            "2025-12-03 16:13:20.521004: Epoch 25\n",
            "2025-12-03 16:13:20.525182: Current learning rate: 0.00977\n",
            "2025-12-03 16:15:54.929237: train_loss 1.0802\n",
            "2025-12-03 16:15:54.933269: val_loss 1.0805\n",
            "2025-12-03 16:15:54.936515: Pseudo dice [np.float32(0.5575), np.float32(0.1518), np.float32(0.0471), np.float32(0.0177), np.float32(0.0146), np.float32(0.5057), np.float32(0.0262), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0024), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0237), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0255), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 16:15:54.939680: Epoch time: 154.41 s\n",
            "2025-12-03 16:15:54.943201: Yayy! New best EMA pseudo Dice: 0.02250000089406967\n",
            "2025-12-03 16:15:56.954568: \n",
            "2025-12-03 16:15:56.957534: Epoch 26\n",
            "2025-12-03 16:15:57.582320: Current learning rate: 0.00977\n",
            "2025-12-03 16:18:34.530296: train_loss 1.0767\n",
            "2025-12-03 16:18:34.533577: val_loss 1.0796\n",
            "2025-12-03 16:18:34.536865: Pseudo dice [np.float32(0.5457), np.float32(0.1881), np.float32(0.0614), np.float32(0.5755), np.float32(0.0202), np.float32(0.0008), np.float32(0.0178), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0151), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0042), np.float32(0.0), np.float32(0.0457), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0959), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
            "2025-12-03 16:18:34.539832: Epoch time: 157.58 s\n",
            "2025-12-03 16:18:34.542604: Yayy! New best EMA pseudo Dice: 0.023600000888109207\n",
            "2025-12-03 16:18:36.487303: \n",
            "2025-12-03 16:18:36.490365: Epoch 27\n",
            "2025-12-03 16:18:36.493851: Current learning rate: 0.00976\n",
            "2025-12-03 16:21:12.574034: train_loss 1.0749\n",
            "2025-12-03 16:21:12.577620: val_loss 1.0748\n",
            "2025-12-03 16:21:12.581628: Pseudo dice [np.float32(0.6081), np.float32(0.1982), np.float32(0.0534), np.float32(0.2027), np.float32(0.0459), np.float32(0.5784), np.float32(0.0799), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0266), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0034), np.float32(0.0), np.float32(0.0351), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0875), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0086)]\n",
            "2025-12-03 16:21:12.585014: Epoch time: 156.09 s\n",
            "2025-12-03 16:21:12.588674: Yayy! New best EMA pseudo Dice: 0.025200000032782555\n",
            "2025-12-03 16:21:14.549343: \n",
            "2025-12-03 16:21:14.552486: Epoch 28\n",
            "2025-12-03 16:21:14.555804: Current learning rate: 0.00975\n",
            "2025-12-03 16:23:53.807232: train_loss 1.0761\n",
            "2025-12-03 16:23:53.810621: val_loss 1.0729\n",
            "2025-12-03 16:23:53.814019: Pseudo dice [np.float32(0.6849), np.float32(0.2156), np.float32(0.0873), np.float32(0.1027), np.float32(0.0643), np.float32(0.5518), np.float32(0.2828), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0785), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0124), np.float32(0.0), np.float32(0.1231), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0692), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0066)]\n",
            "2025-12-03 16:23:53.816760: Epoch time: 159.26 s\n",
            "2025-12-03 16:23:53.819532: Yayy! New best EMA pseudo Dice: 0.027400000020861626\n",
            "2025-12-03 16:23:55.769129: \n",
            "2025-12-03 16:23:55.771802: Epoch 29\n",
            "2025-12-03 16:23:55.774831: Current learning rate: 0.00974\n",
            "2025-12-03 16:26:29.224310: train_loss 1.0755\n",
            "2025-12-03 16:26:29.227551: val_loss 1.0701\n",
            "2025-12-03 16:26:29.231008: Pseudo dice [np.float32(0.6085), np.float32(0.2299), np.float32(0.0394), np.float32(0.0054), np.float32(0.0571), np.float32(0.5854), np.float32(0.236), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0661), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0075), np.float32(0.0), np.float32(0.0336), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0062), np.float32(0.1156), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0073)]\n",
            "2025-12-03 16:26:29.233726: Epoch time: 153.46 s\n",
            "2025-12-03 16:26:29.236572: Yayy! New best EMA pseudo Dice: 0.02889999933540821\n",
            "2025-12-03 16:26:31.199279: \n",
            "2025-12-03 16:26:31.202062: Epoch 30\n",
            "2025-12-03 16:26:31.205392: Current learning rate: 0.00973\n",
            "2025-12-03 16:29:04.707166: train_loss 1.0716\n",
            "2025-12-03 16:29:04.710480: val_loss 1.0678\n",
            "2025-12-03 16:29:04.714039: Pseudo dice [np.float32(0.6405), np.float32(0.2013), np.float32(0.2055), np.float32(0.1056), np.float32(0.1024), np.float32(0.6033), np.float32(0.301), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0163), np.float32(1e-04), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0197), np.float32(0.0), np.float32(0.165), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0974), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0107)]\n",
            "2025-12-03 16:29:04.716629: Epoch time: 153.51 s\n",
            "2025-12-03 16:29:04.719471: Yayy! New best EMA pseudo Dice: 0.031099999323487282\n",
            "2025-12-03 16:29:06.661278: \n",
            "2025-12-03 16:29:06.664226: Epoch 31\n",
            "2025-12-03 16:29:06.667245: Current learning rate: 0.00972\n",
            "2025-12-03 16:31:46.907196: train_loss 1.0739\n",
            "2025-12-03 16:31:46.910632: val_loss 1.0641\n",
            "2025-12-03 16:31:46.914164: Pseudo dice [np.float32(0.7097), np.float32(0.3079), np.float32(0.1248), np.float32(0.3325), np.float32(0.2579), np.float32(0.5069), np.float32(0.2334), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0411), np.float32(0.0118), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0202), np.float32(0.0), np.float32(0.1873), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0056), np.float32(0.1772), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0393)]\n",
            "2025-12-03 16:31:46.929291: Epoch time: 160.25 s\n",
            "2025-12-03 16:31:46.932424: Yayy! New best EMA pseudo Dice: 0.03420000150799751\n",
            "2025-12-03 16:31:49.913988: \n",
            "2025-12-03 16:31:49.917599: Epoch 32\n",
            "2025-12-03 16:31:49.920959: Current learning rate: 0.00971\n",
            "2025-12-03 16:34:40.978759: train_loss 1.0676\n",
            "2025-12-03 16:34:40.982515: val_loss 1.0594\n",
            "2025-12-03 16:34:40.985003: Pseudo dice [np.float32(0.6464), np.float32(0.2855), np.float32(0.0911), np.float32(0.4247), np.float32(0.3676), np.float32(0.4091), np.float32(0.0419), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0417), np.float32(0.1566), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1235), np.float32(0.0), np.float32(0.1199), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0176), np.float32(0.0261), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1031)]\n",
            "2025-12-03 16:34:40.987513: Epoch time: 171.07 s\n",
            "2025-12-03 16:34:40.990310: Yayy! New best EMA pseudo Dice: 0.03669999912381172\n",
            "2025-12-03 16:34:42.890948: \n",
            "2025-12-03 16:34:42.894579: Epoch 33\n",
            "2025-12-03 16:34:42.898394: Current learning rate: 0.0097\n",
            "2025-12-03 16:37:18.706907: train_loss 1.0666\n",
            "2025-12-03 16:37:18.710520: val_loss 1.0775\n",
            "2025-12-03 16:37:18.714721: Pseudo dice [np.float32(0.5596), np.float32(0.3103), np.float32(0.1228), np.float32(0.6781), np.float32(0.2835), np.float32(0.0111), np.float32(0.2286), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0003), np.float32(0.0658), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0347), np.float32(0.0), np.float32(0.1179), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1561), np.float32(0.0107), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0441)]\n",
            "2025-12-03 16:37:18.717366: Epoch time: 155.82 s\n",
            "2025-12-03 16:37:18.720496: Yayy! New best EMA pseudo Dice: 0.03849999979138374\n",
            "2025-12-03 16:37:21.321238: \n",
            "2025-12-03 16:37:21.324033: Epoch 34\n",
            "2025-12-03 16:37:21.327047: Current learning rate: 0.00969\n",
            "2025-12-03 16:39:55.181155: train_loss 1.0639\n",
            "2025-12-03 16:39:55.184824: val_loss 1.0743\n",
            "2025-12-03 16:39:55.188734: Pseudo dice [np.float32(0.5913), np.float32(0.2917), np.float32(0.1393), np.float32(0.0718), np.float32(0.1678), np.float32(0.5139), np.float32(0.3783), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0016), np.float32(0.1336), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(nan), np.float32(0.0249), np.float32(0.0), np.float32(0.1459), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0189), np.float32(0.0712), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1583)]\n",
            "2025-12-03 16:39:55.191937: Epoch time: 153.86 s\n",
            "2025-12-03 16:39:55.195275: Yayy! New best EMA pseudo Dice: 0.04050000011920929\n",
            "2025-12-03 16:39:57.439047: \n",
            "2025-12-03 16:39:57.442059: Epoch 35\n",
            "2025-12-03 16:39:57.445124: Current learning rate: 0.00968\n",
            "2025-12-03 16:42:34.000501: train_loss 1.061\n",
            "2025-12-03 16:42:34.003703: val_loss 1.0595\n",
            "2025-12-03 16:42:34.007064: Pseudo dice [np.float32(0.5893), np.float32(0.2378), np.float32(0.1975), np.float32(0.5642), np.float32(0.0526), np.float32(0.0), np.float32(0.5222), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(1e-04), np.float32(0.1847), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0353), np.float32(0.0), np.float32(0.1729), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0571), np.float32(0.1194), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0221)]\n",
            "2025-12-03 16:42:34.011291: Epoch time: 156.56 s\n",
            "2025-12-03 16:42:34.014163: Yayy! New best EMA pseudo Dice: 0.0421999990940094\n",
            "2025-12-03 16:42:35.933496: \n",
            "2025-12-03 16:42:35.936796: Epoch 36\n",
            "2025-12-03 16:42:35.940119: Current learning rate: 0.00968\n",
            "2025-12-03 16:45:17.765835: train_loss 1.0646\n",
            "2025-12-03 16:45:17.770144: val_loss 1.055\n",
            "2025-12-03 16:45:17.775368: Pseudo dice [np.float32(0.7359), np.float32(0.3051), np.float32(0.2144), np.float32(0.6258), np.float32(0.315), np.float32(0.0837), np.float32(0.411), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.174), np.float32(0.1871), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0902), np.float32(0.0), np.float32(0.1705), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0606), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2351)]\n",
            "2025-12-03 16:45:17.779219: Epoch time: 161.83 s\n",
            "2025-12-03 16:45:17.783322: Yayy! New best EMA pseudo Dice: 0.045499999076128006\n",
            "2025-12-03 16:45:20.609977: \n",
            "2025-12-03 16:45:20.613262: Epoch 37\n",
            "2025-12-03 16:45:20.616205: Current learning rate: 0.00967\n",
            "2025-12-03 16:47:56.696972: train_loss 1.0624\n",
            "2025-12-03 16:47:56.701073: val_loss 1.0585\n",
            "2025-12-03 16:47:56.705278: Pseudo dice [np.float32(0.6062), np.float32(0.1995), np.float32(0.3024), np.float32(0.6214), np.float32(0.1537), np.float32(1e-04), np.float32(0.5121), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0758), np.float32(0.2823), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1461), np.float32(0.0), np.float32(0.1677), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0845), np.float32(0.0352), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0026), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2983)]\n",
            "2025-12-03 16:47:56.708638: Epoch time: 156.09 s\n",
            "2025-12-03 16:47:56.712395: Yayy! New best EMA pseudo Dice: 0.04839999973773956\n",
            "2025-12-03 16:47:58.691112: \n",
            "2025-12-03 16:47:58.694558: Epoch 38\n",
            "2025-12-03 16:47:58.698572: Current learning rate: 0.00966\n",
            "2025-12-03 16:50:32.724441: train_loss 1.0576\n",
            "2025-12-03 16:50:32.728230: val_loss 1.0586\n",
            "2025-12-03 16:50:32.731538: Pseudo dice [np.float32(0.6653), np.float32(0.303), np.float32(0.1269), np.float32(0.079), np.float32(0.3908), np.float32(0.6871), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0093), np.float32(0.2352), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0452), np.float32(0.0), np.float32(0.2784), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2192), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0007), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5018)]\n",
            "2025-12-03 16:50:32.734143: Epoch time: 154.03 s\n",
            "2025-12-03 16:50:32.737405: Yayy! New best EMA pseudo Dice: 0.05090000107884407\n",
            "2025-12-03 16:50:34.663655: \n",
            "2025-12-03 16:50:34.666507: Epoch 39\n",
            "2025-12-03 16:50:34.669373: Current learning rate: 0.00965\n",
            "2025-12-03 16:53:10.935421: train_loss 1.0606\n",
            "2025-12-03 16:53:10.938672: val_loss 1.0688\n",
            "2025-12-03 16:53:10.942131: Pseudo dice [np.float32(0.5805), np.float32(0.2245), np.float32(0.3539), np.float32(0.4754), np.float32(0.0156), np.float32(0.433), np.float32(0.5105), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0004), np.float32(0.2375), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.1694), np.float32(0.0), np.float32(0.1261), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0143), np.float32(0.078), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0052), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2878)]\n",
            "2025-12-03 16:53:10.944760: Epoch time: 156.27 s\n",
            "2025-12-03 16:53:10.947650: Yayy! New best EMA pseudo Dice: 0.053300000727176666\n",
            "2025-12-03 16:53:12.887592: \n",
            "2025-12-03 16:53:12.890856: Epoch 40\n",
            "2025-12-03 16:53:12.893165: Current learning rate: 0.00964\n",
            "2025-12-03 16:55:46.532220: train_loss 1.0566\n",
            "2025-12-03 16:55:46.535689: val_loss 1.0615\n",
            "2025-12-03 16:55:46.539323: Pseudo dice [np.float32(0.6695), np.float32(0.3223), np.float32(0.2874), np.float32(0.5262), np.float32(0.0196), np.float32(0.3343), np.float32(0.5424), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2193), np.float32(0.2717), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0277), np.float32(0.0), np.float32(0.1531), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0114), np.float32(0.1789), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0125), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2945)]\n",
            "2025-12-03 16:55:46.555064: Epoch time: 153.65 s\n",
            "2025-12-03 16:55:46.557892: Yayy! New best EMA pseudo Dice: 0.05620000138878822\n",
            "2025-12-03 16:55:48.435168: \n",
            "2025-12-03 16:55:48.438788: Epoch 41\n",
            "2025-12-03 16:55:48.441706: Current learning rate: 0.00963\n",
            "2025-12-03 16:58:24.947985: train_loss 1.0579\n",
            "2025-12-03 16:58:24.951331: val_loss 1.061\n",
            "2025-12-03 16:58:24.954565: Pseudo dice [np.float32(0.7074), np.float32(0.352), np.float32(0.3211), np.float32(0.3985), np.float32(0.056), np.float32(0.4768), np.float32(0.4807), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0023), np.float32(0.3404), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0803), np.float32(0.0), np.float32(0.2138), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1417), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1396), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2416)]\n",
            "2025-12-03 16:58:24.957240: Epoch time: 156.51 s\n",
            "2025-12-03 16:58:24.960128: Yayy! New best EMA pseudo Dice: 0.058800000697374344\n",
            "2025-12-03 16:58:27.426951: \n",
            "2025-12-03 16:58:27.429748: Epoch 42\n",
            "2025-12-03 16:58:27.432686: Current learning rate: 0.00962\n",
            "2025-12-03 17:01:01.793419: train_loss 1.0514\n",
            "2025-12-03 17:01:01.797073: val_loss 1.061\n",
            "2025-12-03 17:01:01.800841: Pseudo dice [np.float32(0.7189), np.float32(0.4189), np.float32(0.1845), np.float32(0.569), np.float32(0.4088), np.float32(0.0157), np.float32(0.1806), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2917), np.float32(0.1671), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0215), np.float32(0.0), np.float32(0.1713), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1765), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0385), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3442)]\n",
            "2025-12-03 17:01:01.804273: Epoch time: 154.37 s\n",
            "2025-12-03 17:01:01.807999: Yayy! New best EMA pseudo Dice: 0.06069999933242798\n",
            "2025-12-03 17:01:03.717054: \n",
            "2025-12-03 17:01:03.719889: Epoch 43\n",
            "2025-12-03 17:01:03.722889: Current learning rate: 0.00961\n",
            "2025-12-03 17:03:36.761309: train_loss 1.0516\n",
            "2025-12-03 17:03:36.765459: val_loss 1.051\n",
            "2025-12-03 17:03:36.768421: Pseudo dice [np.float32(0.6929), np.float32(0.4329), np.float32(0.2162), np.float32(0.4908), np.float32(0.2387), np.float32(0.4359), np.float32(0.4051), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3069), np.float32(0.0445), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0533), np.float32(0.0), np.float32(0.1631), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1611), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0672), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4002)]\n",
            "2025-12-03 17:03:36.771863: Epoch time: 153.05 s\n",
            "2025-12-03 17:03:36.774967: Yayy! New best EMA pseudo Dice: 0.0632999986410141\n",
            "2025-12-03 17:03:38.633990: \n",
            "2025-12-03 17:03:38.636768: Epoch 44\n",
            "2025-12-03 17:03:38.639891: Current learning rate: 0.0096\n",
            "2025-12-03 17:06:12.680945: train_loss 1.0504\n",
            "2025-12-03 17:06:12.696794: val_loss 1.0484\n",
            "2025-12-03 17:06:12.700380: Pseudo dice [np.float32(0.6865), np.float32(0.3986), np.float32(0.3845), np.float32(0.2406), np.float32(0.001), np.float32(0.633), np.float32(0.5442), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3229), np.float32(0.2761), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0749), np.float32(0.0), np.float32(0.1857), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3222), np.float32(0.0072), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3669), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5831)]\n",
            "2025-12-03 17:06:12.703061: Epoch time: 154.05 s\n",
            "2025-12-03 17:06:12.706127: Yayy! New best EMA pseudo Dice: 0.06750000268220901\n",
            "2025-12-03 17:06:14.537621: \n",
            "2025-12-03 17:06:14.542558: Epoch 45\n",
            "2025-12-03 17:06:14.545749: Current learning rate: 0.00959\n",
            "2025-12-03 17:08:48.614403: train_loss 1.0495\n",
            "2025-12-03 17:08:48.617751: val_loss 1.0492\n",
            "2025-12-03 17:08:48.621763: Pseudo dice [np.float32(0.7671), np.float32(0.4019), np.float32(0.2439), np.float32(0.6309), np.float32(0.0532), np.float32(0.0127), np.float32(0.4429), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3237), np.float32(0.3454), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0165), np.float32(0.0), np.float32(0.1157), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3293), np.float32(0.0021), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4249), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4604)]\n",
            "2025-12-03 17:08:48.624754: Epoch time: 154.08 s\n",
            "2025-12-03 17:08:48.628259: Yayy! New best EMA pseudo Dice: 0.07029999792575836\n",
            "2025-12-03 17:08:50.496830: \n",
            "2025-12-03 17:08:50.499509: Epoch 46\n",
            "2025-12-03 17:08:51.119815: Current learning rate: 0.00959\n",
            "2025-12-03 17:11:27.888113: train_loss 1.046\n",
            "2025-12-03 17:11:27.892720: val_loss 1.0458\n",
            "2025-12-03 17:11:27.897936: Pseudo dice [np.float32(0.7788), np.float32(0.3665), np.float32(0.2644), np.float32(0.5855), np.float32(0.4468), np.float32(0.157), np.float32(0.1617), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1365), np.float32(0.3954), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0506), np.float32(0.0), np.float32(0.1798), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2918), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4125), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5982)]\n",
            "2025-12-03 17:11:27.902626: Epoch time: 157.39 s\n",
            "2025-12-03 17:11:27.907191: Yayy! New best EMA pseudo Dice: 0.07329999655485153\n",
            "2025-12-03 17:11:30.070487: \n",
            "2025-12-03 17:11:30.073672: Epoch 47\n",
            "2025-12-03 17:11:30.077315: Current learning rate: 0.00958\n",
            "2025-12-03 17:14:17.779470: train_loss 1.0463\n",
            "2025-12-03 17:14:17.783146: val_loss 1.0429\n",
            "2025-12-03 17:14:17.786656: Pseudo dice [np.float32(0.7461), np.float32(0.4514), np.float32(0.3766), np.float32(0.5501), np.float32(0.0009), np.float32(0.3191), np.float32(0.5168), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.212), np.float32(0.386), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0578), np.float32(0.0), np.float32(0.1868), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3012), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.432), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5183)]\n",
            "2025-12-03 17:14:17.790013: Epoch time: 167.71 s\n",
            "2025-12-03 17:14:17.793595: Yayy! New best EMA pseudo Dice: 0.07649999856948853\n",
            "2025-12-03 17:14:20.324742: \n",
            "2025-12-03 17:14:20.327467: Epoch 48\n",
            "2025-12-03 17:14:20.330576: Current learning rate: 0.00957\n",
            "2025-12-03 17:16:55.237044: train_loss 1.0431\n",
            "2025-12-03 17:16:55.240956: val_loss 1.0437\n",
            "2025-12-03 17:16:55.245185: Pseudo dice [np.float32(0.7449), np.float32(0.2686), np.float32(0.4288), np.float32(0.1772), np.float32(0.4871), np.float32(0.5817), np.float32(0.0079), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0674), np.float32(0.4044), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0421), np.float32(0.0), np.float32(0.2003), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3758), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3405), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.6766)]\n",
            "2025-12-03 17:16:55.248143: Epoch time: 154.91 s\n",
            "2025-12-03 17:16:55.251450: Yayy! New best EMA pseudo Dice: 0.07880000025033951\n",
            "2025-12-03 17:16:57.153619: \n",
            "2025-12-03 17:16:57.156972: Epoch 49\n",
            "2025-12-03 17:16:57.160554: Current learning rate: 0.00956\n",
            "2025-12-03 17:19:30.774707: train_loss 1.0387\n",
            "2025-12-03 17:19:30.778305: val_loss 1.0427\n",
            "2025-12-03 17:19:30.782069: Pseudo dice [np.float32(0.701), np.float32(0.1603), np.float32(0.5025), np.float32(0.0799), np.float32(0.0), np.float32(0.6009), np.float32(0.4817), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0268), np.float32(0.4547), np.float32(0.0219), np.float32(0.0076), np.float32(0.0), np.float32(0.0), np.float32(0.0284), np.float32(0.0), np.float32(0.1944), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3731), np.float32(0.0556), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.52), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.6528)]\n",
            "2025-12-03 17:19:30.785051: Epoch time: 153.62 s\n",
            "2025-12-03 17:19:31.333180: Yayy! New best EMA pseudo Dice: 0.08110000193119049\n",
            "2025-12-03 17:19:33.256560: \n",
            "2025-12-03 17:19:33.259423: Epoch 50\n",
            "2025-12-03 17:19:33.262408: Current learning rate: 0.00955\n",
            "2025-12-03 17:22:07.740749: train_loss 1.0432\n",
            "2025-12-03 17:22:07.744090: val_loss 1.0443\n",
            "2025-12-03 17:22:07.747733: Pseudo dice [np.float32(0.6889), np.float32(0.2963), np.float32(0.4151), np.float32(0.3945), np.float32(0.4338), np.float32(0.5107), np.float32(0.014), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0735), np.float32(0.408), np.float32(0.002), np.float32(0.0047), np.float32(0.0), np.float32(0.0), np.float32(0.1069), np.float32(0.0), np.float32(0.1246), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3535), np.float32(0.3183), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3379), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5485)]\n",
            "2025-12-03 17:22:07.750497: Epoch time: 154.49 s\n",
            "2025-12-03 17:22:07.753335: Yayy! New best EMA pseudo Dice: 0.08349999785423279\n",
            "2025-12-03 17:22:10.271500: \n",
            "2025-12-03 17:22:10.274409: Epoch 51\n",
            "2025-12-03 17:22:10.277318: Current learning rate: 0.00954\n",
            "2025-12-03 17:24:49.370092: train_loss 1.0405\n",
            "2025-12-03 17:24:49.373363: val_loss 1.0395\n",
            "2025-12-03 17:24:49.376599: Pseudo dice [np.float32(0.8022), np.float32(0.2976), np.float32(0.4335), np.float32(0.0869), np.float32(0.3218), np.float32(0.5378), np.float32(0.4099), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3467), np.float32(0.1851), np.float32(0.0351), np.float32(0.0356), np.float32(0.0), np.float32(0.0), np.float32(0.1323), np.float32(0.0), np.float32(0.1832), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.365), np.float32(0.369), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4168), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5724)]\n",
            "2025-12-03 17:24:49.379076: Epoch time: 159.1 s\n",
            "2025-12-03 17:24:49.381992: Yayy! New best EMA pseudo Dice: 0.08659999817609787\n",
            "2025-12-03 17:24:51.285563: \n",
            "2025-12-03 17:24:51.288469: Epoch 52\n",
            "2025-12-03 17:24:51.292333: Current learning rate: 0.00953\n",
            "2025-12-03 17:27:25.559408: train_loss 1.0386\n",
            "2025-12-03 17:27:25.562972: val_loss 1.0424\n",
            "2025-12-03 17:27:25.566449: Pseudo dice [np.float32(0.7614), np.float32(0.4271), np.float32(0.3466), np.float32(0.2951), np.float32(0.4981), np.float32(0.5906), np.float32(0.3574), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0196), np.float32(0.4544), np.float32(0.1958), np.float32(0.0003), np.float32(0.0), np.float32(0.0), np.float32(0.0375), np.float32(0.0), np.float32(0.1748), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1377), np.float32(0.3655), np.float32(0.3333), np.float32(0.002), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0002), np.float32(0.5722), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.6107)]\n",
            "2025-12-03 17:27:25.568954: Epoch time: 154.28 s\n",
            "2025-12-03 17:27:25.571735: Yayy! New best EMA pseudo Dice: 0.09080000221729279\n",
            "2025-12-03 17:27:27.494367: \n",
            "2025-12-03 17:27:27.497084: Epoch 53\n",
            "2025-12-03 17:27:27.500285: Current learning rate: 0.00952\n",
            "2025-12-03 17:30:10.124151: train_loss 1.0371\n",
            "2025-12-03 17:30:10.129271: val_loss 1.0429\n",
            "2025-12-03 17:30:10.134235: Pseudo dice [np.float32(0.805), np.float32(0.342), np.float32(0.4233), np.float32(0.4344), np.float32(0.0007), np.float32(0.4874), np.float32(0.4744), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4118), np.float32(0.2785), np.float32(0.1922), np.float32(0.2666), np.float32(0.0), np.float32(nan), np.float32(0.0244), np.float32(0.0), np.float32(0.1531), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0426), np.float32(0.3973), np.float32(0.3563), np.float32(0.0083), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.6186), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.464)]\n",
            "2025-12-03 17:30:10.138042: Epoch time: 162.63 s\n",
            "2025-12-03 17:30:10.142091: Yayy! New best EMA pseudo Dice: 0.09489999711513519\n",
            "2025-12-03 17:30:12.409072: \n",
            "2025-12-03 17:30:12.413010: Epoch 54\n",
            "2025-12-03 17:30:12.417977: Current learning rate: 0.00951\n",
            "2025-12-03 17:32:55.106901: train_loss 1.0322\n",
            "2025-12-03 17:32:55.110269: val_loss 1.0418\n",
            "2025-12-03 17:32:55.113610: Pseudo dice [np.float32(0.8022), np.float32(0.3737), np.float32(0.4151), np.float32(0.6051), np.float32(0.5231), np.float32(0.2759), np.float32(0.0468), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3248), np.float32(0.4053), np.float32(0.2361), np.float32(0.0024), np.float32(0.0), np.float32(0.0), np.float32(0.0031), np.float32(0.0), np.float32(0.2302), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.545), np.float32(0.0456), np.float32(0.3414), np.float32(0.0483), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5911), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.7341)]\n",
            "2025-12-03 17:32:55.116156: Epoch time: 162.7 s\n",
            "2025-12-03 17:32:55.119182: Yayy! New best EMA pseudo Dice: 0.09939999878406525\n",
            "2025-12-03 17:32:56.987209: \n",
            "2025-12-03 17:32:56.990111: Epoch 55\n",
            "2025-12-03 17:32:56.993188: Current learning rate: 0.0095\n",
            "2025-12-03 17:35:30.681710: train_loss 1.0317\n",
            "2025-12-03 17:35:30.685443: val_loss 1.0319\n",
            "2025-12-03 17:35:30.688909: Pseudo dice [np.float32(0.8128), np.float32(0.4815), np.float32(0.3625), np.float32(0.4615), np.float32(0.4225), np.float32(0.4724), np.float32(0.3232), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4523), np.float32(0.0354), np.float32(0.2991), np.float32(0.0322), np.float32(0.0), np.float32(0.0), np.float32(0.0082), np.float32(0.0), np.float32(0.2265), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4031), np.float32(0.3316), np.float32(0.0036), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3542), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4165)]\n",
            "2025-12-03 17:35:30.691819: Epoch time: 153.7 s\n",
            "2025-12-03 17:35:30.705458: Yayy! New best EMA pseudo Dice: 0.10170000046491623\n",
            "2025-12-03 17:35:32.616381: \n",
            "2025-12-03 17:35:32.619712: Epoch 56\n",
            "2025-12-03 17:35:32.622988: Current learning rate: 0.00949\n",
            "2025-12-03 17:38:06.021221: train_loss 1.0326\n",
            "2025-12-03 17:38:06.024416: val_loss 1.0254\n",
            "2025-12-03 17:38:06.027841: Pseudo dice [np.float32(0.8086), np.float32(0.4772), np.float32(0.4438), np.float32(0.5302), np.float32(0.3691), np.float32(0.0114), np.float32(0.396), np.float32(0.0029), np.float32(0.0), np.float32(0.0), np.float32(0.4224), np.float32(0.3582), np.float32(0.3983), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0156), np.float32(0.0), np.float32(0.1431), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4717), np.float32(0.0586), np.float32(0.4338), np.float32(0.0623), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5619), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5501)]\n",
            "2025-12-03 17:38:06.030286: Epoch time: 153.41 s\n",
            "2025-12-03 17:38:06.033162: Yayy! New best EMA pseudo Dice: 0.10509999841451645\n",
            "2025-12-03 17:38:07.895092: \n",
            "2025-12-03 17:38:07.898376: Epoch 57\n",
            "2025-12-03 17:38:07.902205: Current learning rate: 0.00949\n",
            "2025-12-03 17:40:41.946161: train_loss 1.0333\n",
            "2025-12-03 17:40:41.950310: val_loss 1.0376\n",
            "2025-12-03 17:40:41.954360: Pseudo dice [np.float32(0.8227), np.float32(0.4273), np.float32(0.4492), np.float32(0.6667), np.float32(0.4344), np.float32(0.0587), np.float32(0.4529), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4242), np.float32(0.4205), np.float32(0.3425), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0106), np.float32(0.0), np.float32(0.2113), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3056), np.float32(0.3069), np.float32(0.4296), np.float32(0.0087), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0316), np.float32(0.357), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.7514)]\n",
            "2025-12-03 17:40:41.957126: Epoch time: 154.05 s\n",
            "2025-12-03 17:40:41.960295: Yayy! New best EMA pseudo Dice: 0.10899999737739563\n",
            "2025-12-03 17:40:44.773009: \n",
            "2025-12-03 17:40:44.776208: Epoch 58\n",
            "2025-12-03 17:40:44.779714: Current learning rate: 0.00948\n",
            "2025-12-03 17:43:20.230529: train_loss 1.0258\n",
            "2025-12-03 17:43:20.235168: val_loss 1.0393\n",
            "2025-12-03 17:43:20.238940: Pseudo dice [np.float32(0.8166), np.float32(0.384), np.float32(0.4293), np.float32(0.0778), np.float32(0.0287), np.float32(0.6333), np.float32(0.5402), np.float32(0.0019), np.float32(0.0), np.float32(0.0), np.float32(0.4207), np.float32(0.3681), np.float32(0.3047), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0184), np.float32(0.0), np.float32(0.2449), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1389), np.float32(0.4274), np.float32(0.444), np.float32(0.1085), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(nan), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1224), np.float32(0.53), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5992)]\n",
            "2025-12-03 17:43:20.242428: Epoch time: 155.46 s\n",
            "2025-12-03 17:43:20.246525: Yayy! New best EMA pseudo Dice: 0.11219999939203262\n",
            "2025-12-03 17:43:22.188978: \n",
            "2025-12-03 17:43:22.191980: Epoch 59\n",
            "2025-12-03 17:43:22.195504: Current learning rate: 0.00947\n",
            "2025-12-03 17:45:55.946557: train_loss 1.0296\n",
            "2025-12-03 17:45:55.950238: val_loss 1.0329\n",
            "2025-12-03 17:45:55.953458: Pseudo dice [np.float32(0.8169), np.float32(0.4801), np.float32(0.4561), np.float32(0.5812), np.float32(0.5314), np.float32(0.0589), np.float32(0.2107), np.float32(0.0091), np.float32(0.0), np.float32(0.0), np.float32(0.4444), np.float32(0.2368), np.float32(0.2865), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0212), np.float32(0.0), np.float32(0.2124), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4233), np.float32(0.2441), np.float32(0.4405), np.float32(0.0646), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0469), np.float32(0.471), np.float32(0.0004), np.float32(0.0), np.float32(0.0), np.float32(0.6867)]\n",
            "2025-12-03 17:45:55.957412: Epoch time: 153.76 s\n",
            "2025-12-03 17:45:55.961361: Yayy! New best EMA pseudo Dice: 0.11500000208616257\n",
            "2025-12-03 17:45:57.946299: \n",
            "2025-12-03 17:45:57.949586: Epoch 60\n",
            "2025-12-03 17:45:57.953366: Current learning rate: 0.00946\n",
            "2025-12-03 17:48:31.611047: train_loss 1.0211\n",
            "2025-12-03 17:48:31.615992: val_loss 1.0243\n",
            "2025-12-03 17:48:31.620725: Pseudo dice [np.float32(0.858), np.float32(0.4198), np.float32(0.4891), np.float32(0.6009), np.float32(0.4706), np.float32(0.2369), np.float32(0.4055), np.float32(0.0002), np.float32(0.0), np.float32(0.0), np.float32(0.4353), np.float32(0.2586), np.float32(0.2782), np.float32(0.2251), np.float32(0.0), np.float32(0.0), np.float32(0.0464), np.float32(0.0), np.float32(0.3364), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1205), np.float32(0.3667), np.float32(0.4993), np.float32(0.0759), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0049), np.float32(0.5652), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4758)]\n",
            "2025-12-03 17:48:31.623985: Epoch time: 153.67 s\n",
            "2025-12-03 17:48:31.627662: Yayy! New best EMA pseudo Dice: 0.11840000003576279\n",
            "2025-12-03 17:48:33.755941: \n",
            "2025-12-03 17:48:33.758691: Epoch 61\n",
            "2025-12-03 17:48:33.761808: Current learning rate: 0.00945\n",
            "2025-12-03 17:51:10.519728: train_loss 1.0265\n",
            "2025-12-03 17:51:10.524392: val_loss 1.0379\n",
            "2025-12-03 17:51:10.541028: Pseudo dice [np.float32(0.8001), np.float32(0.2838), np.float32(0.4457), np.float32(0.5939), np.float32(0.0677), np.float32(0.1019), np.float32(0.4993), np.float32(0.002), np.float32(0.0), np.float32(0.0), np.float32(0.1728), np.float32(0.4504), np.float32(0.3866), np.float32(0.0086), np.float32(0.0), np.float32(0.0), np.float32(0.0059), np.float32(0.0), np.float32(0.2612), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.478), np.float32(0.1675), np.float32(0.3817), np.float32(0.1716), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2156), np.float32(0.5561), np.float32(0.0188), np.float32(0.0), np.float32(0.0), np.float32(0.7375)]\n",
            "2025-12-03 17:51:10.544414: Epoch time: 156.76 s\n",
            "2025-12-03 17:51:10.547959: Yayy! New best EMA pseudo Dice: 0.12080000340938568\n",
            "2025-12-03 17:51:12.536071: \n",
            "2025-12-03 17:51:12.539927: Epoch 62\n",
            "2025-12-03 17:51:12.543557: Current learning rate: 0.00944\n",
            "2025-12-03 17:53:46.028318: train_loss 1.022\n",
            "2025-12-03 17:53:46.032151: val_loss 1.0293\n",
            "2025-12-03 17:53:46.036249: Pseudo dice [np.float32(0.8606), np.float32(0.3214), np.float32(0.4746), np.float32(0.518), np.float32(0.0265), np.float32(0.3415), np.float32(0.5423), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4622), np.float32(0.0505), np.float32(0.2772), np.float32(0.0041), np.float32(0.0), np.float32(0.0), np.float32(0.0195), np.float32(0.0), np.float32(0.2805), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1803), np.float32(0.3081), np.float32(0.4437), np.float32(0.0836), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1131), np.float32(0.6155), np.float32(0.0777), np.float32(0.0), np.float32(0.0), np.float32(0.3772)]\n",
            "2025-12-03 17:53:46.039614: Epoch time: 153.49 s\n",
            "2025-12-03 17:53:46.043062: Yayy! New best EMA pseudo Dice: 0.12200000137090683\n",
            "2025-12-03 17:53:48.015764: \n",
            "2025-12-03 17:53:48.018585: Epoch 63\n",
            "2025-12-03 17:53:48.643667: Current learning rate: 0.00943\n",
            "2025-12-03 17:56:30.138921: train_loss 1.0207\n",
            "2025-12-03 17:56:30.142224: val_loss 1.0288\n",
            "2025-12-03 17:56:30.145900: Pseudo dice [np.float32(0.8266), np.float32(0.5402), np.float32(0.3575), np.float32(0.6544), np.float32(0.5533), np.float32(0.1934), np.float32(0.0), np.float32(0.0149), np.float32(0.0), np.float32(0.0), np.float32(0.4564), np.float32(0.2141), np.float32(0.003), np.float32(0.2635), np.float32(0.0), np.float32(0.0), np.float32(0.3064), np.float32(0.0), np.float32(0.0925), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3485), np.float32(0.327), np.float32(0.4984), np.float32(0.0936), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2281), np.float32(0.5316), np.float32(0.1456), np.float32(0.0), np.float32(0.0), np.float32(0.7902)]\n",
            "2025-12-03 17:56:30.148807: Epoch time: 162.12 s\n",
            "2025-12-03 17:56:30.152165: Yayy! New best EMA pseudo Dice: 0.12530000507831573\n",
            "2025-12-03 17:56:32.749964: \n",
            "2025-12-03 17:56:32.753616: Epoch 64\n",
            "2025-12-03 17:56:32.757584: Current learning rate: 0.00942\n",
            "2025-12-03 17:59:18.687731: train_loss 1.0252\n",
            "2025-12-03 17:59:18.691738: val_loss 1.0302\n",
            "2025-12-03 17:59:18.696449: Pseudo dice [np.float32(0.8198), np.float32(0.3818), np.float32(0.2931), np.float32(0.5635), np.float32(0.4128), np.float32(0.1516), np.float32(0.0886), np.float32(0.0625), np.float32(0.0), np.float32(0.0), np.float32(0.3092), np.float32(0.3928), np.float32(0.28), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0505), np.float32(0.0), np.float32(0.26), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3808), np.float32(0.0081), np.float32(0.4109), np.float32(0.1812), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2774), np.float32(0.6276), np.float32(0.2219), np.float32(0.0), np.float32(0.0), np.float32(0.6234)]\n",
            "2025-12-03 17:59:18.699928: Epoch time: 165.94 s\n",
            "2025-12-03 17:59:18.703705: Yayy! New best EMA pseudo Dice: 0.12690000236034393\n",
            "2025-12-03 17:59:21.166452: \n",
            "2025-12-03 17:59:21.511120: Epoch 65\n",
            "2025-12-03 17:59:21.514482: Current learning rate: 0.00941\n",
            "2025-12-03 18:02:01.973079: train_loss 1.023\n",
            "2025-12-03 18:02:01.978162: val_loss 1.0335\n",
            "2025-12-03 18:02:01.983475: Pseudo dice [np.float32(0.7981), np.float32(0.1797), np.float32(0.4607), np.float32(0.5613), np.float32(0.0003), np.float32(0.3467), np.float32(0.5096), np.float32(0.0296), np.float32(0.0), np.float32(0.0), np.float32(0.5012), np.float32(0.206), np.float32(0.2825), np.float32(0.0096), np.float32(0.0), np.float32(0.0), np.float32(0.0146), np.float32(0.0), np.float32(0.3049), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2467), np.float32(0.394), np.float32(0.3948), np.float32(0.2265), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4079), np.float32(0.5762), np.float32(0.2297), np.float32(0.0), np.float32(0.0), np.float32(0.6822)]\n",
            "2025-12-03 18:02:01.987311: Epoch time: 160.81 s\n",
            "2025-12-03 18:02:02.003435: Yayy! New best EMA pseudo Dice: 0.12960000336170197\n",
            "2025-12-03 18:02:04.179592: \n",
            "2025-12-03 18:02:04.182612: Epoch 66\n",
            "2025-12-03 18:02:04.186753: Current learning rate: 0.0094\n",
            "2025-12-03 18:04:37.706516: train_loss 1.0177\n",
            "2025-12-03 18:04:37.710619: val_loss 1.0327\n",
            "2025-12-03 18:04:37.715313: Pseudo dice [np.float32(0.7958), np.float32(0.253), np.float32(0.4921), np.float32(0.0935), np.float32(0.0009), np.float32(0.6243), np.float32(0.5336), np.float32(0.0379), np.float32(0.0), np.float32(0.0), np.float32(0.4663), np.float32(0.2376), np.float32(0.406), np.float32(0.0009), np.float32(0.0), np.float32(0.0), np.float32(0.1227), np.float32(0.0), np.float32(0.2549), np.float32(0.0004), np.float32(0.0), np.float32(0.0), np.float32(0.4584), np.float32(0.1047), np.float32(0.3417), np.float32(0.2749), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3196), np.float32(0.5052), np.float32(0.4382), np.float32(0.0), np.float32(0.0), np.float32(0.6671)]\n",
            "2025-12-03 18:04:37.718859: Epoch time: 153.53 s\n",
            "2025-12-03 18:04:37.722828: Yayy! New best EMA pseudo Dice: 0.13210000097751617\n",
            "2025-12-03 18:04:39.834336: \n",
            "2025-12-03 18:04:40.457199: Epoch 67\n",
            "2025-12-03 18:04:40.460833: Current learning rate: 0.00939\n",
            "2025-12-03 18:07:23.481394: train_loss 1.0198\n",
            "2025-12-03 18:07:23.485214: val_loss 1.0226\n",
            "2025-12-03 18:07:23.489052: Pseudo dice [np.float32(0.8386), np.float32(0.4216), np.float32(0.4653), np.float32(0.6191), np.float32(0.08), np.float32(0.0523), np.float32(0.5474), np.float32(0.0956), np.float32(0.0), np.float32(0.0), np.float32(0.4152), np.float32(0.3178), np.float32(0.3431), np.float32(0.0054), np.float32(0.0), np.float32(0.0), np.float32(0.0738), np.float32(0.0), np.float32(0.3986), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0276), np.float32(0.4983), np.float32(0.4717), np.float32(0.1646), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2504), np.float32(0.6363), np.float32(0.4024), np.float32(0.0), np.float32(0.0), np.float32(0.7107)]\n",
            "2025-12-03 18:07:23.492024: Epoch time: 163.65 s\n",
            "2025-12-03 18:07:23.495185: Yayy! New best EMA pseudo Dice: 0.13519999384880066\n",
            "2025-12-03 18:07:25.515614: \n",
            "2025-12-03 18:07:25.519129: Epoch 68\n",
            "2025-12-03 18:07:25.523613: Current learning rate: 0.00939\n",
            "2025-12-03 18:10:00.819643: train_loss 1.0174\n",
            "2025-12-03 18:10:00.822979: val_loss 1.0268\n",
            "2025-12-03 18:10:00.826390: Pseudo dice [np.float32(0.8406), np.float32(0.1342), np.float32(0.4097), np.float32(0.0266), np.float32(0.1473), np.float32(0.6239), np.float32(0.5289), np.float32(0.0812), np.float32(0.0), np.float32(0.0), np.float32(0.4267), np.float32(0.1694), np.float32(0.2919), np.float32(0.3274), np.float32(0.0), np.float32(0.0), np.float32(0.0151), np.float32(0.0), np.float32(0.3328), np.float32(0.0011), np.float32(0.0003), np.float32(0.0), np.float32(0.4422), np.float32(0.2795), np.float32(0.3319), np.float32(0.1942), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3976), np.float32(0.4577), np.float32(0.4665), np.float32(0.0), np.float32(0.0), np.float32(0.671)]\n",
            "2025-12-03 18:10:00.828872: Epoch time: 155.31 s\n",
            "2025-12-03 18:10:00.831817: Yayy! New best EMA pseudo Dice: 0.13750000298023224\n",
            "2025-12-03 18:10:02.716172: \n",
            "2025-12-03 18:10:02.718844: Epoch 69\n",
            "2025-12-03 18:10:02.721834: Current learning rate: 0.00938\n",
            "2025-12-03 18:12:36.775460: train_loss 1.0169\n",
            "2025-12-03 18:12:36.779667: val_loss 1.0287\n",
            "2025-12-03 18:12:36.786654: Pseudo dice [np.float32(0.8711), np.float32(0.3795), np.float32(0.3895), np.float32(0.6128), np.float32(0.12), np.float32(0.0876), np.float32(0.4603), np.float32(0.0452), np.float32(0.0), np.float32(0.0), np.float32(0.4956), np.float32(0.0855), np.float32(0.1921), np.float32(0.3451), np.float32(0.0), np.float32(0.0), np.float32(0.3769), np.float32(0.0), np.float32(0.0011), np.float32(0.0), np.float32(0.0019), np.float32(0.0), np.float32(1e-04), np.float32(0.4439), np.float32(0.3775), np.float32(0.2011), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2946), np.float32(0.4531), np.float32(0.4013), np.float32(0.0), np.float32(0.0), np.float32(0.6231)]\n",
            "2025-12-03 18:12:36.790180: Epoch time: 154.06 s\n",
            "2025-12-03 18:12:36.794011: Yayy! New best EMA pseudo Dice: 0.1388999968767166\n",
            "2025-12-03 18:12:39.665581: \n",
            "2025-12-03 18:12:40.302347: Epoch 70\n",
            "2025-12-03 18:12:40.307444: Current learning rate: 0.00937\n",
            "2025-12-03 18:15:16.882830: train_loss 1.0098\n",
            "2025-12-03 18:15:16.886623: val_loss 1.0203\n",
            "2025-12-03 18:15:16.890896: Pseudo dice [np.float32(0.8484), np.float32(0.3316), np.float32(0.4504), np.float32(0.2684), np.float32(0.0653), np.float32(0.4823), np.float32(0.6042), np.float32(0.1059), np.float32(0.0), np.float32(0.0163), np.float32(0.4908), np.float32(0.2532), np.float32(0.3491), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0335), np.float32(0.0), np.float32(0.2625), np.float32(0.0005), np.float32(0.0014), np.float32(0.0038), np.float32(0.4101), np.float32(0.1101), np.float32(0.3528), np.float32(0.2435), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0906), np.float32(0.4863), np.float32(0.2972), np.float32(0.0), np.float32(0.0), np.float32(0.5305)]\n",
            "2025-12-03 18:15:16.894075: Epoch time: 157.22 s\n",
            "2025-12-03 18:15:16.897494: Yayy! New best EMA pseudo Dice: 0.13979999721050262\n",
            "2025-12-03 18:15:18.865192: \n",
            "2025-12-03 18:15:18.868245: Epoch 71\n",
            "2025-12-03 18:15:18.871523: Current learning rate: 0.00936\n",
            "2025-12-03 18:17:59.627890: train_loss 1.0099\n",
            "2025-12-03 18:17:59.631882: val_loss 1.012\n",
            "2025-12-03 18:17:59.637643: Pseudo dice [np.float32(0.863), np.float32(0.4724), np.float32(0.4473), np.float32(0.247), np.float32(0.349), np.float32(0.541), np.float32(0.4113), np.float32(0.2274), np.float32(0.0), np.float32(0.2607), np.float32(0.4532), np.float32(0.4615), np.float32(0.4352), np.float32(0.0461), np.float32(0.0), np.float32(0.0), np.float32(0.1328), np.float32(0.0), np.float32(0.3205), np.float32(0.0051), np.float32(0.0421), np.float32(0.0045), np.float32(0.3472), np.float32(0.0297), np.float32(0.461), np.float32(0.197), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2631), np.float32(0.3853), np.float32(0.3986), np.float32(0.0), np.float32(0.0), np.float32(0.6524)]\n",
            "2025-12-03 18:17:59.642336: Epoch time: 160.76 s\n",
            "2025-12-03 18:17:59.646206: Yayy! New best EMA pseudo Dice: 0.14339999854564667\n",
            "2025-12-03 18:18:01.945729: \n",
            "2025-12-03 18:18:02.570004: Epoch 72\n",
            "2025-12-03 18:18:02.572593: Current learning rate: 0.00935\n",
            "2025-12-03 18:20:39.529114: train_loss 1.0124\n",
            "2025-12-03 18:20:39.532993: val_loss 1.026\n",
            "2025-12-03 18:20:39.536994: Pseudo dice [np.float32(0.767), np.float32(0.3831), np.float32(0.4416), np.float32(0.4514), np.float32(0.0065), np.float32(0.4223), np.float32(0.5066), np.float32(0.197), np.float32(0.0), np.float32(0.2614), np.float32(0.3802), np.float32(0.3322), np.float32(0.2308), np.float32(0.2829), np.float32(0.0), np.float32(0.0), np.float32(0.1233), np.float32(0.0), np.float32(0.3925), np.float32(0.035), np.float32(0.0097), np.float32(0.0117), np.float32(0.199), np.float32(0.3673), np.float32(0.3496), np.float32(0.2224), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3598), np.float32(0.4672), np.float32(0.4951), np.float32(0.0), np.float32(0.0), np.float32(0.8315)]\n",
            "2025-12-03 18:20:39.539548: Epoch time: 157.58 s\n",
            "2025-12-03 18:20:39.542336: Yayy! New best EMA pseudo Dice: 0.1467999964952469\n",
            "2025-12-03 18:20:41.468858: \n",
            "2025-12-03 18:20:41.471587: Epoch 73\n",
            "2025-12-03 18:20:41.475008: Current learning rate: 0.00934\n",
            "2025-12-03 18:23:16.248851: train_loss 1.0115\n",
            "2025-12-03 18:23:16.253164: val_loss 1.0182\n",
            "2025-12-03 18:23:16.256994: Pseudo dice [np.float32(0.8378), np.float32(0.4214), np.float32(0.3639), np.float32(0.573), np.float32(0.2186), np.float32(0.2091), np.float32(0.5169), np.float32(0.1412), np.float32(0.0), np.float32(0.1802), np.float32(0.4754), np.float32(0.2626), np.float32(0.1905), np.float32(0.3057), np.float32(0.0), np.float32(0.0), np.float32(0.0198), np.float32(0.0), np.float32(0.3528), np.float32(0.0111), np.float32(0.0083), np.float32(0.0322), np.float32(0.3142), np.float32(0.2547), np.float32(0.351), np.float32(0.2534), np.float32(0.0135), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0198), np.float32(nan), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3995), np.float32(0.4308), np.float32(0.4535), np.float32(0.0), np.float32(0.0), np.float32(0.6126)]\n",
            "2025-12-03 18:23:16.260736: Epoch time: 154.78 s\n",
            "2025-12-03 18:23:16.264516: Yayy! New best EMA pseudo Dice: 0.14959999918937683\n",
            "2025-12-03 18:23:19.236065: \n",
            "2025-12-03 18:23:19.240202: Epoch 74\n",
            "2025-12-03 18:23:19.245207: Current learning rate: 0.00933\n",
            "2025-12-03 18:25:54.285936: train_loss 1.0032\n",
            "2025-12-03 18:25:54.289207: val_loss 1.0212\n",
            "2025-12-03 18:25:54.292869: Pseudo dice [np.float32(0.8569), np.float32(0.2895), np.float32(0.5048), np.float32(0.3417), np.float32(0.4067), np.float32(0.6331), np.float32(0.4322), np.float32(0.1805), np.float32(0.0), np.float32(0.28), np.float32(0.4607), np.float32(0.2641), np.float32(0.0008), np.float32(0.3357), np.float32(0.0), np.float32(0.0), np.float32(0.0501), np.float32(0.0), np.float32(0.4392), np.float32(0.0266), np.float32(0.0245), np.float32(0.0405), np.float32(0.2888), np.float32(0.0834), np.float32(0.3492), np.float32(0.364), np.float32(0.0034), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2506), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.298), np.float32(0.4887), np.float32(0.4185), np.float32(0.0), np.float32(0.0), np.float32(0.8035)]\n",
            "2025-12-03 18:25:54.295799: Epoch time: 155.05 s\n",
            "2025-12-03 18:25:54.298931: Yayy! New best EMA pseudo Dice: 0.15330000221729279\n",
            "2025-12-03 18:25:56.306950: \n",
            "2025-12-03 18:25:56.310309: Epoch 75\n",
            "2025-12-03 18:25:56.618783: Current learning rate: 0.00932\n",
            "2025-12-03 18:28:40.649905: train_loss 1.0072\n",
            "2025-12-03 18:28:40.664068: val_loss 1.0124\n",
            "2025-12-03 18:28:40.668324: Pseudo dice [np.float32(0.8424), np.float32(0.2494), np.float32(0.4542), np.float32(0.5831), np.float32(0.0069), np.float32(0.3575), np.float32(0.4355), np.float32(0.2024), np.float32(0.0), np.float32(0.2634), np.float32(0.5007), np.float32(0.2691), np.float32(0.1141), np.float32(0.3262), np.float32(0.0), np.float32(0.0), np.float32(1e-04), np.float32(0.0), np.float32(0.2115), np.float32(0.0294), np.float32(0.0049), np.float32(0.0237), np.float32(0.4725), np.float32(0.0003), np.float32(0.4109), np.float32(0.3365), np.float32(0.0724), np.float32(0.0), np.float32(0.0), np.float32(0.001), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3219), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3752), np.float32(0.6281), np.float32(0.314), np.float32(0.0), np.float32(0.0), np.float32(0.7402)]\n",
            "2025-12-03 18:28:40.671987: Epoch time: 164.34 s\n",
            "2025-12-03 18:28:40.676180: Yayy! New best EMA pseudo Dice: 0.15569999814033508\n",
            "2025-12-03 18:28:42.814622: \n",
            "2025-12-03 18:28:42.817650: Epoch 76\n",
            "2025-12-03 18:28:42.821230: Current learning rate: 0.00931\n",
            "2025-12-03 18:31:31.647915: train_loss 1.0074\n",
            "2025-12-03 18:31:31.651874: val_loss 1.0168\n",
            "2025-12-03 18:31:31.655722: Pseudo dice [np.float32(0.8538), np.float32(0.533), np.float32(0.4404), np.float32(0.5977), np.float32(0.4553), np.float32(0.0017), np.float32(0.3286), np.float32(0.2343), np.float32(0.0), np.float32(0.1421), np.float32(0.3965), np.float32(0.3718), np.float32(0.3948), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0038), np.float32(0.0), np.float32(0.3435), np.float32(0.0853), np.float32(0.1169), np.float32(0.0294), np.float32(0.0602), np.float32(0.3105), np.float32(0.386), np.float32(0.3208), np.float32(0.0375), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1079), np.float32(0.2451), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1396), np.float32(0.5092), np.float32(0.4131), np.float32(0.0), np.float32(0.0), np.float32(0.6326)]\n",
            "2025-12-03 18:31:31.658823: Epoch time: 168.83 s\n",
            "2025-12-03 18:31:31.673321: Yayy! New best EMA pseudo Dice: 0.15790000557899475\n",
            "2025-12-03 18:31:34.031697: \n",
            "2025-12-03 18:31:34.034897: Epoch 77\n",
            "2025-12-03 18:31:34.038430: Current learning rate: 0.0093\n",
            "2025-12-03 18:34:08.359917: train_loss 1.0052\n",
            "2025-12-03 18:34:08.363503: val_loss 1.0109\n",
            "2025-12-03 18:34:08.366850: Pseudo dice [np.float32(0.8369), np.float32(0.5014), np.float32(0.5009), np.float32(0.3494), np.float32(0.0403), np.float32(0.5699), np.float32(0.4982), np.float32(0.3649), np.float32(0.0081), np.float32(0.268), np.float32(0.5647), np.float32(0.2909), np.float32(0.4127), np.float32(0.0236), np.float32(0.0), np.float32(0.0), np.float32(0.009), np.float32(0.0), np.float32(0.3351), np.float32(0.0598), np.float32(0.0762), np.float32(0.052), np.float32(0.2133), np.float32(0.3854), np.float32(0.5333), np.float32(0.3981), np.float32(0.045), np.float32(0.0), np.float32(0.0), np.float32(0.0029), np.float32(0.0), np.float32(0.0), np.float32(0.02), np.float32(0.3441), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2626), np.float32(0.4401), np.float32(0.4258), np.float32(0.0), np.float32(0.0), np.float32(0.7333)]\n",
            "2025-12-03 18:34:08.380575: Epoch time: 154.33 s\n",
            "2025-12-03 18:34:08.383992: Yayy! New best EMA pseudo Dice: 0.16200000047683716\n",
            "2025-12-03 18:34:10.404958: \n",
            "2025-12-03 18:34:10.407807: Epoch 78\n",
            "2025-12-03 18:34:10.411218: Current learning rate: 0.0093\n",
            "2025-12-03 18:36:45.168377: train_loss 0.9989\n",
            "2025-12-03 18:36:45.172971: val_loss 1.0102\n",
            "2025-12-03 18:36:45.177500: Pseudo dice [np.float32(0.8516), np.float32(0.2782), np.float32(0.4603), np.float32(0.0444), np.float32(0.3389), np.float32(0.5929), np.float32(0.4851), np.float32(0.2515), np.float32(0.007), np.float32(0.3741), np.float32(0.4788), np.float32(0.3625), np.float32(0.4208), np.float32(0.0568), np.float32(0.0), np.float32(0.0), np.float32(0.0013), np.float32(0.0), np.float32(0.2973), np.float32(0.0956), np.float32(0.0861), np.float32(0.0943), np.float32(0.3001), np.float32(0.4067), np.float32(0.4703), np.float32(0.364), np.float32(0.0682), np.float32(0.0), np.float32(0.0), np.float32(0.1677), np.float32(0.0), np.float32(0.0), np.float32(0.0172), np.float32(0.3011), np.float32(0.0), np.float32(0.0), np.float32(0.0002), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1075), np.float32(0.0), np.float32(0.3843), np.float32(0.6124), np.float32(0.5052), np.float32(0.0), np.float32(0.0), np.float32(0.8293)]\n",
            "2025-12-03 18:36:45.181144: Epoch time: 154.76 s\n",
            "2025-12-03 18:36:45.185300: Yayy! New best EMA pseudo Dice: 0.16689999401569366\n",
            "2025-12-03 18:36:47.314533: \n",
            "2025-12-03 18:36:47.940555: Epoch 79\n",
            "2025-12-03 18:36:47.945983: Current learning rate: 0.00929\n",
            "2025-12-03 18:39:21.700993: train_loss 0.9974\n",
            "2025-12-03 18:39:21.704257: val_loss 1.0181\n",
            "2025-12-03 18:39:21.707535: Pseudo dice [np.float32(0.8453), np.float32(0.4075), np.float32(0.4005), np.float32(0.5913), np.float32(0.1249), np.float32(0.1561), np.float32(0.5673), np.float32(0.2869), np.float32(0.0023), np.float32(0.3714), np.float32(0.5796), np.float32(0.4905), np.float32(0.4364), np.float32(0.0998), np.float32(0.0), np.float32(0.0), np.float32(0.0207), np.float32(0.0139), np.float32(0.3493), np.float32(0.0768), np.float32(0.0653), np.float32(0.0069), np.float32(0.0349), np.float32(0.4427), np.float32(0.4307), np.float32(0.2183), np.float32(0.0104), np.float32(0.0019), np.float32(0.0202), np.float32(0.1968), np.float32(0.0), np.float32(0.0), np.float32(0.2263), np.float32(0.3937), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1208), np.float32(0.0163), np.float32(0.4353), np.float32(0.5904), np.float32(0.4098), np.float32(0.0), np.float32(0.0), np.float32(0.7967)]\n",
            "2025-12-03 18:39:21.710090: Epoch time: 154.39 s\n",
            "2025-12-03 18:39:21.712797: Yayy! New best EMA pseudo Dice: 0.17149999737739563\n",
            "2025-12-03 18:39:23.690036: \n",
            "2025-12-03 18:39:23.693753: Epoch 80\n",
            "2025-12-03 18:39:23.697402: Current learning rate: 0.00928\n",
            "2025-12-03 18:42:02.986878: train_loss 0.9965\n",
            "2025-12-03 18:42:02.991102: val_loss 1.0057\n",
            "2025-12-03 18:42:02.995539: Pseudo dice [np.float32(0.8456), np.float32(0.338), np.float32(0.369), np.float32(0.5139), np.float32(0.1203), np.float32(0.429), np.float32(0.5043), np.float32(0.2648), np.float32(0.0114), np.float32(0.3346), np.float32(0.5017), np.float32(0.3625), np.float32(0.0967), np.float32(0.3859), np.float32(0.0), np.float32(0.0), np.float32(0.0043), np.float32(0.0), np.float32(0.3281), np.float32(0.0491), np.float32(1e-04), np.float32(0.1637), np.float32(0.3878), np.float32(0.321), np.float32(0.4006), np.float32(0.3294), np.float32(0.0736), np.float32(0.0), np.float32(0.0238), np.float32(0.1802), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2967), np.float32(0.0), np.float32(0.0), np.float32(0.1399), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1538), np.float32(0.0051), np.float32(0.3687), np.float32(0.6019), np.float32(0.5176), np.float32(0.0), np.float32(0.0), np.float32(0.7887)]\n",
            "2025-12-03 18:42:02.999030: Epoch time: 159.3 s\n",
            "2025-12-03 18:42:03.003001: Yayy! New best EMA pseudo Dice: 0.17560000717639923\n",
            "2025-12-03 18:42:06.037150: \n",
            "2025-12-03 18:42:06.039989: Epoch 81\n",
            "2025-12-03 18:42:06.043233: Current learning rate: 0.00927\n",
            "2025-12-03 18:44:40.449159: train_loss 0.988\n",
            "2025-12-03 18:44:40.457809: val_loss 1.0081\n",
            "2025-12-03 18:44:40.465851: Pseudo dice [np.float32(0.8445), np.float32(0.3601), np.float32(0.3992), np.float32(0.3701), np.float32(0.0763), np.float32(0.5618), np.float32(0.5339), np.float32(0.3507), np.float32(0.0), np.float32(0.3602), np.float32(0.5394), np.float32(0.3706), np.float32(0.4019), np.float32(0.1343), np.float32(0.0), np.float32(nan), np.float32(0.1041), np.float32(0.1476), np.float32(0.4907), np.float32(0.1044), np.float32(0.0), np.float32(0.1472), np.float32(0.0019), np.float32(0.5206), np.float32(0.3611), np.float32(0.2633), np.float32(0.1077), np.float32(0.0217), np.float32(0.0577), np.float32(0.2395), np.float32(0.0), np.float32(0.0), np.float32(0.2327), np.float32(0.4758), np.float32(nan), np.float32(0.0), np.float32(0.016), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0041), np.float32(0.2928), np.float32(0.459), np.float32(0.7681), np.float32(0.4746), np.float32(0.0), np.float32(0.0), np.float32(0.8171)]\n",
            "2025-12-03 18:44:40.470160: Epoch time: 154.41 s\n",
            "2025-12-03 18:44:40.474595: Yayy! New best EMA pseudo Dice: 0.18289999663829803\n",
            "2025-12-03 18:44:42.772906: \n",
            "2025-12-03 18:44:42.777232: Epoch 82\n",
            "2025-12-03 18:44:42.783685: Current learning rate: 0.00926\n",
            "2025-12-03 18:47:25.751965: train_loss 0.9885\n",
            "2025-12-03 18:47:25.755555: val_loss 1.0045\n",
            "2025-12-03 18:47:25.758930: Pseudo dice [np.float32(0.8155), np.float32(0.5593), np.float32(0.4491), np.float32(0.6292), np.float32(0.5664), np.float32(0.1736), np.float32(0.0), np.float32(0.3456), np.float32(0.0), np.float32(0.4739), np.float32(0.5116), np.float32(0.41), np.float32(0.4034), np.float32(0.1385), np.float32(0.0), np.float32(0.0), np.float32(0.0386), np.float32(0.0), np.float32(0.3833), np.float32(0.1113), np.float32(0.0), np.float32(0.1814), np.float32(0.4946), np.float32(0.1424), np.float32(0.4882), np.float32(0.4253), np.float32(0.0695), np.float32(0.0047), np.float32(0.0148), np.float32(0.2005), np.float32(0.0), np.float32(0.0), np.float32(0.1346), np.float32(0.3914), np.float32(0.0), np.float32(0.0), np.float32(0.0492), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2043), np.float32(0.089), np.float32(0.1977), np.float32(0.5805), np.float32(0.5984), np.float32(0.0), np.float32(0.0), np.float32(0.3878)]\n",
            "2025-12-03 18:47:25.761611: Epoch time: 162.98 s\n",
            "2025-12-03 18:47:25.765125: Yayy! New best EMA pseudo Dice: 0.1868000030517578\n",
            "2025-12-03 18:47:27.730431: \n",
            "2025-12-03 18:47:27.733639: Epoch 83\n",
            "2025-12-03 18:47:27.736618: Current learning rate: 0.00925\n",
            "2025-12-03 18:50:03.425960: train_loss 0.9964\n",
            "2025-12-03 18:50:03.429589: val_loss 1.0062\n",
            "2025-12-03 18:50:03.434224: Pseudo dice [np.float32(0.8328), np.float32(0.3775), np.float32(0.4445), np.float32(0.4493), np.float32(0.016), np.float32(0.4809), np.float32(0.4499), np.float32(0.4517), np.float32(0.0105), np.float32(0.5414), np.float32(0.545), np.float32(0.3934), np.float32(0.307), np.float32(0.2763), np.float32(0.0), np.float32(0.0), np.float32(0.4395), np.float32(0.1657), np.float32(0.1698), np.float32(0.0078), np.float32(0.1305), np.float32(0.0475), np.float32(0.1933), np.float32(0.501), np.float32(0.3927), np.float32(0.448), np.float32(0.1083), np.float32(0.0), np.float32(0.0), np.float32(0.2702), np.float32(0.0), np.float32(0.0), np.float32(0.3397), np.float32(0.0021), np.float32(0.0), np.float32(0.0), np.float32(0.2506), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0025), np.float32(0.2901), np.float32(0.4911), np.float32(0.6001), np.float32(0.6135), np.float32(0.0), np.float32(0.0), np.float32(0.5926)]\n",
            "2025-12-03 18:50:03.449455: Epoch time: 155.7 s\n",
            "2025-12-03 18:50:03.453667: Yayy! New best EMA pseudo Dice: 0.1923999935388565\n",
            "2025-12-03 18:50:05.384046: \n",
            "2025-12-03 18:50:05.387059: Epoch 84\n",
            "2025-12-03 18:50:05.390174: Current learning rate: 0.00924\n",
            "2025-12-03 18:52:44.568353: train_loss 0.9895\n",
            "2025-12-03 18:52:44.571725: val_loss 1.0001\n",
            "2025-12-03 18:52:44.575281: Pseudo dice [np.float32(0.8225), np.float32(0.4822), np.float32(0.4869), np.float32(0.6079), np.float32(0.116), np.float32(0.1552), np.float32(0.4454), np.float32(0.375), np.float32(0.122), np.float32(0.5616), np.float32(0.5314), np.float32(0.3273), np.float32(0.4785), np.float32(0.181), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3514), np.float32(0.1166), np.float32(0.0), np.float32(0.2227), np.float32(0.4228), np.float32(0.0629), np.float32(0.6086), np.float32(0.4891), np.float32(0.1492), np.float32(0.0), np.float32(0.0), np.float32(0.3113), np.float32(0.0), np.float32(0.0029), np.float32(0.0953), np.float32(0.3482), np.float32(0.0), np.float32(0.0), np.float32(0.0868), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.1531), np.float32(0.0005), np.float32(0.2785), np.float32(0.5603), np.float32(0.5778), np.float32(0.0), np.float32(0.0), np.float32(0.7992)]\n",
            "2025-12-03 18:52:44.577830: Epoch time: 159.19 s\n",
            "2025-12-03 18:52:44.580589: Yayy! New best EMA pseudo Dice: 0.19670000672340393\n",
            "2025-12-03 18:52:46.497316: \n",
            "2025-12-03 18:52:46.500024: Epoch 85\n",
            "2025-12-03 18:52:46.503138: Current learning rate: 0.00923\n",
            "2025-12-03 18:55:22.212973: train_loss 0.991\n",
            "2025-12-03 18:55:22.216292: val_loss 1.006\n",
            "2025-12-03 18:55:22.219556: Pseudo dice [np.float32(0.846), np.float32(0.3517), np.float32(0.4639), np.float32(0.4629), np.float32(0.002), np.float32(0.5646), np.float32(0.5299), np.float32(0.2966), np.float32(0.0207), np.float32(0.5899), np.float32(0.5207), np.float32(0.4317), np.float32(0.3414), np.float32(0.3205), np.float32(0.0), np.float32(0.0), np.float32(0.2514), np.float32(0.1661), np.float32(0.3966), np.float32(0.0), np.float32(0.0), np.float32(0.1591), np.float32(0.0019), np.float32(0.4316), np.float32(0.4176), np.float32(0.3706), np.float32(0.1945), np.float32(0.0008), np.float32(0.0), np.float32(0.2156), np.float32(0.0), np.float32(0.001), np.float32(0.3959), np.float32(0.014), np.float32(0.0), np.float32(0.0), np.float32(0.3452), np.float32(0.0038), np.float32(0.0013), np.float32(0.0), np.float32(0.2068), np.float32(0.0369), np.float32(0.5141), np.float32(0.6268), np.float32(0.5908), np.float32(0.0), np.float32(0.0047), np.float32(0.6549)]\n",
            "2025-12-03 18:55:22.222380: Epoch time: 155.72 s\n",
            "2025-12-03 18:55:22.225245: Yayy! New best EMA pseudo Dice: 0.20149999856948853\n",
            "2025-12-03 18:55:24.116653: \n",
            "2025-12-03 18:55:24.119437: Epoch 86\n",
            "2025-12-03 18:55:24.122544: Current learning rate: 0.00922\n",
            "2025-12-03 18:57:58.892877: train_loss 0.988\n",
            "2025-12-03 18:57:58.896136: val_loss 1.0086\n",
            "2025-12-03 18:57:58.909427: Pseudo dice [np.float32(0.8545), np.float32(0.5266), np.float32(0.3465), np.float32(0.7043), np.float32(0.654), np.float32(0.0), np.float32(0.0), np.float32(0.41), np.float32(0.0115), np.float32(0.6642), np.float32(0.5893), np.float32(0.427), np.float32(0.3565), np.float32(0.019), np.float32(0.0), np.float32(0.0), np.float32(0.1233), np.float32(0.1672), np.float32(0.3202), np.float32(0.1563), np.float32(0.0), np.float32(0.1952), np.float32(0.2716), np.float32(0.3605), np.float32(0.3493), np.float32(0.3808), np.float32(0.1639), np.float32(0.0726), np.float32(0.0165), np.float32(0.312), np.float32(0.0), np.float32(0.0575), np.float32(0.4407), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4086), np.float32(0.0053), np.float32(0.0), np.float32(0.0), np.float32(0.0104), np.float32(0.1833), np.float32(0.4893), np.float32(0.6849), np.float32(0.5655), np.float32(0.0), np.float32(0.0), np.float32(0.7348)]\n",
            "2025-12-03 18:57:58.912433: Epoch time: 154.78 s\n",
            "2025-12-03 18:57:58.915432: Yayy! New best EMA pseudo Dice: 0.20640000700950623\n",
            "2025-12-03 18:58:00.854751: \n",
            "2025-12-03 18:58:00.858170: Epoch 87\n",
            "2025-12-03 18:58:00.861297: Current learning rate: 0.00921\n",
            "2025-12-03 19:00:34.649912: train_loss 0.9914\n",
            "2025-12-03 19:00:34.653281: val_loss 1.0128\n",
            "2025-12-03 19:00:34.656689: Pseudo dice [np.float32(0.8125), np.float32(0.2243), np.float32(0.4192), np.float32(0.2338), np.float32(0.1), np.float32(0.5625), np.float32(0.4331), np.float32(0.3652), np.float32(0.0608), np.float32(0.5769), np.float32(0.5375), np.float32(0.3432), np.float32(0.0005), np.float32(0.3654), np.float32(0.0013), np.float32(0.0), np.float32(0.0002), np.float32(0.0), np.float32(0.359), np.float32(0.1069), np.float32(0.0659), np.float32(0.1995), np.float32(0.3332), np.float32(0.4503), np.float32(0.0939), np.float32(0.33), np.float32(0.2365), np.float32(0.0139), np.float32(0.0035), np.float32(0.2791), np.float32(0.0), np.float32(0.0008), np.float32(0.3897), np.float32(0.1066), np.float32(0.0), np.float32(0.0), np.float32(0.1587), np.float32(0.1218), np.float32(0.0059), np.float32(0.0), np.float32(0.0), np.float32(0.2862), np.float32(0.5269), np.float32(0.6775), np.float32(0.649), np.float32(0.0), np.float32(0.003), np.float32(0.7528)]\n",
            "2025-12-03 19:00:34.659166: Epoch time: 153.8 s\n",
            "2025-12-03 19:00:34.661941: Yayy! New best EMA pseudo Dice: 0.20909999310970306\n",
            "2025-12-03 19:00:36.557177: \n",
            "2025-12-03 19:00:36.559990: Epoch 88\n",
            "2025-12-03 19:00:36.562684: Current learning rate: 0.0092\n",
            "2025-12-03 19:03:10.686314: train_loss 0.9855\n",
            "2025-12-03 19:03:10.689704: val_loss 0.9985\n",
            "2025-12-03 19:03:10.693266: Pseudo dice [np.float32(0.853), np.float32(0.4035), np.float32(0.5115), np.float32(0.3779), np.float32(0.1793), np.float32(0.5677), np.float32(0.5087), np.float32(0.2759), np.float32(0.1241), np.float32(0.4391), np.float32(0.41), np.float32(0.4213), np.float32(0.2483), np.float32(0.3802), np.float32(0.0128), np.float32(0.0), np.float32(0.0024), np.float32(0.2019), np.float32(0.4018), np.float32(0.0205), np.float32(0.2436), np.float32(0.0083), np.float32(0.2841), np.float32(0.2394), np.float32(0.4548), np.float32(0.4866), np.float32(0.109), np.float32(0.0352), np.float32(0.2134), np.float32(0.1368), np.float32(0.0), np.float32(0.0), np.float32(0.4155), np.float32(0.0014), np.float32(0.0), np.float32(0.0), np.float32(0.3165), np.float32(0.2905), np.float32(0.0179), np.float32(0.0), np.float32(0.0), np.float32(0.3236), np.float32(0.4582), np.float32(0.7498), np.float32(0.483), np.float32(0.0), np.float32(0.0151), np.float32(0.3517)]\n",
            "2025-12-03 19:03:10.696023: Epoch time: 154.13 s\n",
            "2025-12-03 19:03:10.698955: Yayy! New best EMA pseudo Dice: 0.21310000121593475\n",
            "2025-12-03 19:03:12.635133: \n",
            "2025-12-03 19:03:12.638232: Epoch 89\n",
            "2025-12-03 19:03:12.641911: Current learning rate: 0.0092\n",
            "2025-12-03 19:05:50.420770: train_loss 0.9918\n",
            "2025-12-03 19:05:50.424601: val_loss 1.017\n",
            "2025-12-03 19:05:50.428257: Pseudo dice [np.float32(0.8627), np.float32(0.3441), np.float32(0.3887), np.float32(0.4012), np.float32(0.5299), np.float32(0.4856), np.float32(0.0), np.float32(0.2405), np.float32(0.0262), np.float32(0.6535), np.float32(0.4698), np.float32(0.3122), np.float32(0.439), np.float32(0.0003), np.float32(0.0), np.float32(0.0), np.float32(0.4242), np.float32(0.1671), np.float32(0.0), np.float32(0.0), np.float32(0.0851), np.float32(0.235), np.float32(0.058), np.float32(0.498), np.float32(0.316), np.float32(0.4303), np.float32(0.2721), np.float32(0.0), np.float32(0.2195), np.float32(0.1386), np.float32(0.0), np.float32(0.0066), np.float32(0.4346), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0725), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0002), np.float32(0.2702), np.float32(0.544), np.float32(0.7195), np.float32(0.5391), np.float32(0.0), np.float32(0.0), np.float32(0.5802)]\n",
            "2025-12-03 19:05:50.431163: Epoch time: 157.79 s\n",
            "2025-12-03 19:05:50.445724: Yayy! New best EMA pseudo Dice: 0.2151000052690506\n",
            "2025-12-03 19:05:52.411554: \n",
            "2025-12-03 19:05:52.414581: Epoch 90\n",
            "2025-12-03 19:05:52.417525: Current learning rate: 0.00919\n",
            "2025-12-03 19:08:28.860360: train_loss 0.9855\n",
            "2025-12-03 19:08:28.863808: val_loss 1.0112\n",
            "2025-12-03 19:08:28.867980: Pseudo dice [np.float32(0.7744), np.float32(0.2719), np.float32(0.4718), np.float32(0.0398), np.float32(0.0133), np.float32(0.5863), np.float32(0.4808), np.float32(0.3723), np.float32(0.0988), np.float32(0.6007), np.float32(0.4162), np.float32(0.355), np.float32(0.0699), np.float32(0.3662), np.float32(0.0), np.float32(0.0), np.float32(0.0174), np.float32(0.0), np.float32(0.4679), np.float32(0.1852), np.float32(0.0083), np.float32(0.282), np.float32(0.3879), np.float32(0.3969), np.float32(0.3442), np.float32(0.3765), np.float32(0.1612), np.float32(0.1323), np.float32(1e-04), np.float32(0.2365), np.float32(0.0), np.float32(0.0577), np.float32(0.0002), np.float32(0.4328), np.float32(0.0), np.float32(0.0383), np.float32(0.0), np.float32(0.4571), np.float32(0.0243), np.float32(0.0), np.float32(0.0), np.float32(0.4158), np.float32(0.5752), np.float32(0.7029), np.float32(0.588), np.float32(0.0), np.float32(0.0004), np.float32(0.7783)]\n",
            "2025-12-03 19:08:28.870828: Epoch time: 156.45 s\n",
            "2025-12-03 19:08:28.874080: Yayy! New best EMA pseudo Dice: 0.21850000321865082\n",
            "2025-12-03 19:08:30.866183: \n",
            "2025-12-03 19:08:30.869114: Epoch 91\n",
            "2025-12-03 19:08:30.872216: Current learning rate: 0.00918\n",
            "2025-12-03 19:11:11.896930: train_loss 0.9849\n",
            "2025-12-03 19:11:11.900727: val_loss 0.9984\n",
            "2025-12-03 19:11:11.904233: Pseudo dice [np.float32(0.853), np.float32(0.3675), np.float32(0.4723), np.float32(0.0643), np.float32(0.0002), np.float32(0.5953), np.float32(0.504), np.float32(0.3925), np.float32(0.1365), np.float32(0.7375), np.float32(0.3841), np.float32(0.3167), np.float32(0.4919), np.float32(0.0292), np.float32(0.0021), np.float32(0.0), np.float32(0.0468), np.float32(0.1705), np.float32(0.4433), np.float32(0.0006), np.float32(0.2251), np.float32(0.0), np.float32(0.3405), np.float32(0.3467), np.float32(0.337), np.float32(0.2713), np.float32(0.1139), np.float32(0.0388), np.float32(0.0), np.float32(0.2997), np.float32(0.0), np.float32(0.028), np.float32(0.0391), np.float32(0.3626), np.float32(0.0), np.float32(0.0), np.float32(0.205), np.float32(0.0), np.float32(0.0078), np.float32(0.001), np.float32(0.0), np.float32(0.329), np.float32(0.5478), np.float32(0.7736), np.float32(0.5478), np.float32(0.0), np.float32(0.0), np.float32(0.834)]\n",
            "2025-12-03 19:11:11.906908: Epoch time: 161.03 s\n",
            "2025-12-03 19:11:11.909964: Yayy! New best EMA pseudo Dice: 0.22100000083446503\n",
            "2025-12-03 19:11:13.806322: \n",
            "2025-12-03 19:11:13.809353: Epoch 92\n",
            "2025-12-03 19:11:13.812752: Current learning rate: 0.00917\n",
            "2025-12-03 19:13:53.468480: train_loss 0.977\n",
            "2025-12-03 19:13:53.472690: val_loss 1.0108\n",
            "2025-12-03 19:13:53.475873: Pseudo dice [np.float32(0.8373), np.float32(0.5361), np.float32(0.3871), np.float32(0.0476), np.float32(0.1745), np.float32(0.5401), np.float32(0.388), np.float32(0.4658), np.float32(0.0923), np.float32(0.6454), np.float32(0.5528), np.float32(0.4164), np.float32(0.381), np.float32(0.0492), np.float32(0.0006), np.float32(0.0), np.float32(0.1225), np.float32(0.0), np.float32(0.2698), np.float32(0.04), np.float32(0.1999), np.float32(0.0023), np.float32(0.1103), np.float32(0.5306), np.float32(0.4181), np.float32(0.337), np.float32(0.1955), np.float32(0.062), np.float32(0.0291), np.float32(0.2703), np.float32(0.0), np.float32(0.0742), np.float32(0.0), np.float32(0.3645), np.float32(0.0), np.float32(0.0124), np.float32(0.1513), np.float32(0.1593), np.float32(0.1608), np.float32(0.0023), np.float32(0.0), np.float32(0.2167), np.float32(0.4289), np.float32(0.6653), np.float32(0.4981), np.float32(0.0), np.float32(0.0), np.float32(0.8314)]\n",
            "2025-12-03 19:13:53.479484: Epoch time: 159.66 s\n",
            "2025-12-03 19:13:53.483355: Yayy! New best EMA pseudo Dice: 0.2231999933719635\n",
            "2025-12-03 19:13:55.638558: \n",
            "2025-12-03 19:13:55.641676: Epoch 93\n",
            "2025-12-03 19:13:55.645262: Current learning rate: 0.00916\n",
            "2025-12-03 19:16:30.301565: train_loss 0.9858\n",
            "2025-12-03 19:16:30.305211: val_loss 0.9967\n",
            "2025-12-03 19:16:30.318808: Pseudo dice [np.float32(0.8571), np.float32(0.55), np.float32(0.5692), np.float32(0.5974), np.float32(0.4399), np.float32(0.0293), np.float32(0.2915), np.float32(0.3885), np.float32(0.042), np.float32(0.5281), np.float32(0.4895), np.float32(0.329), np.float32(0.0797), np.float32(0.3717), np.float32(0.0337), np.float32(0.0), np.float32(0.3166), np.float32(0.0), np.float32(0.4161), np.float32(0.1948), np.float32(0.0), np.float32(0.3284), np.float32(0.3833), np.float32(0.3762), np.float32(0.5184), np.float32(0.3311), np.float32(0.2163), np.float32(0.0), np.float32(0.0), np.float32(0.3151), np.float32(0.0), np.float32(0.1225), np.float32(0.2934), np.float32(0.4307), np.float32(0.0), np.float32(0.043), np.float32(0.1174), np.float32(0.0), np.float32(0.0017), np.float32(0.0322), np.float32(0.0), np.float32(0.4502), np.float32(0.2416), np.float32(0.5735), np.float32(0.5162), np.float32(0.0), np.float32(0.0037), np.float32(0.8416)]\n",
            "2025-12-03 19:16:30.321912: Epoch time: 154.66 s\n",
            "2025-12-03 19:16:30.325009: Yayy! New best EMA pseudo Dice: 0.2272000014781952\n",
            "2025-12-03 19:16:32.276742: \n",
            "2025-12-03 19:16:32.280225: Epoch 94\n",
            "2025-12-03 19:16:32.283733: Current learning rate: 0.00915\n",
            "2025-12-03 19:19:11.349508: train_loss 0.9884\n",
            "2025-12-03 19:19:11.354865: val_loss 0.999\n",
            "2025-12-03 19:19:11.360092: Pseudo dice [np.float32(0.8427), np.float32(0.4599), np.float32(0.5432), np.float32(0.5968), np.float32(0.4982), np.float32(0.1083), np.float32(0.094), np.float32(0.1897), np.float32(0.0154), np.float32(0.6115), np.float32(0.3973), np.float32(0.4894), np.float32(0.4216), np.float32(0.0271), np.float32(0.0), np.float32(0.0), np.float32(0.2406), np.float32(0.0118), np.float32(0.4301), np.float32(0.2116), np.float32(0.017), np.float32(0.2536), np.float32(0.3645), np.float32(0.42), np.float32(0.464), np.float32(0.4755), np.float32(0.1284), np.float32(0.0005), np.float32(0.0), np.float32(0.2775), np.float32(0.0), np.float32(0.1101), np.float32(0.4627), np.float32(0.0088), np.float32(0.0), np.float32(0.0), np.float32(0.0372), np.float32(0.2509), np.float32(0.0), np.float32(0.0), np.float32(0.0006), np.float32(0.2704), np.float32(0.6084), np.float32(0.7446), np.float32(0.5772), np.float32(0.0), np.float32(0.004), np.float32(0.8162)]\n",
            "2025-12-03 19:19:11.364573: Epoch time: 159.07 s\n",
            "2025-12-03 19:19:11.368750: Yayy! New best EMA pseudo Dice: 0.2304999977350235\n",
            "2025-12-03 19:19:13.387501: \n",
            "2025-12-03 19:19:13.390347: Epoch 95\n",
            "2025-12-03 19:19:13.393619: Current learning rate: 0.00914\n",
            "2025-12-03 19:21:46.512164: train_loss 0.9844\n",
            "2025-12-03 19:21:46.515985: val_loss 1.0029\n",
            "2025-12-03 19:21:46.519294: Pseudo dice [np.float32(0.8338), np.float32(0.4652), np.float32(0.3468), np.float32(0.331), np.float32(0.0913), np.float32(0.4844), np.float32(0.4903), np.float32(0.5368), np.float32(0.0557), np.float32(0.6708), np.float32(0.507), np.float32(0.2058), np.float32(0.3831), np.float32(0.2526), np.float32(0.0029), np.float32(nan), np.float32(0.2532), np.float32(0.2508), np.float32(0.4503), np.float32(0.0303), np.float32(0.0722), np.float32(0.3071), np.float32(0.2292), np.float32(0.3983), np.float32(0.4197), np.float32(0.3551), np.float32(0.0895), np.float32(0.0506), np.float32(0.0), np.float32(0.2626), np.float32(0.0), np.float32(0.1392), np.float32(0.0862), np.float32(0.4274), np.float32(0.0042), np.float32(nan), np.float32(0.5238), np.float32(0.0031), np.float32(0.0141), np.float32(0.0), np.float32(0.3267), np.float32(0.0011), np.float32(0.6137), np.float32(0.7812), np.float32(0.5928), np.float32(0.0), np.float32(0.0), np.float32(0.7694)]\n",
            "2025-12-03 19:21:46.522110: Epoch time: 153.13 s\n",
            "2025-12-03 19:21:46.524956: Yayy! New best EMA pseudo Dice: 0.23600000143051147\n",
            "2025-12-03 19:21:49.086290: \n",
            "2025-12-03 19:21:49.089575: Epoch 96\n",
            "2025-12-03 19:21:49.092940: Current learning rate: 0.00913\n",
            "2025-12-03 19:24:22.376616: train_loss 0.9826\n",
            "2025-12-03 19:24:22.380544: val_loss 0.9996\n",
            "2025-12-03 19:24:22.383966: Pseudo dice [np.float32(0.8517), np.float32(0.3983), np.float32(0.3866), np.float32(0.2292), np.float32(0.0173), np.float32(0.574), np.float32(0.488), np.float32(0.4377), np.float32(0.0), np.float32(0.5685), np.float32(0.4981), np.float32(0.4092), np.float32(0.4335), np.float32(0.0682), np.float32(0.0028), np.float32(0.0), np.float32(0.0965), np.float32(0.0), np.float32(0.4081), np.float32(0.1477), np.float32(0.0752), np.float32(0.243), np.float32(0.1472), np.float32(0.6326), np.float32(0.4325), np.float32(0.4287), np.float32(0.1942), np.float32(0.0015), np.float32(0.0), np.float32(0.2865), np.float32(0.0), np.float32(0.2593), np.float32(0.005), np.float32(0.4425), np.float32(0.0), np.float32(0.0), np.float32(0.2213), np.float32(0.2181), np.float32(0.0), np.float32(0.0143), np.float32(0.1822), np.float32(0.0012), np.float32(0.5267), np.float32(0.6125), np.float32(0.5869), np.float32(0.0), np.float32(0.0), np.float32(0.819)]\n",
            "2025-12-03 19:24:22.387126: Epoch time: 153.29 s\n",
            "2025-12-03 19:24:22.390210: Yayy! New best EMA pseudo Dice: 0.23810000717639923\n",
            "2025-12-03 19:24:24.348145: \n",
            "2025-12-03 19:24:24.350987: Epoch 97\n",
            "2025-12-03 19:24:24.354028: Current learning rate: 0.00912\n",
            "2025-12-03 19:26:57.737999: train_loss 0.9783\n",
            "2025-12-03 19:26:57.741686: val_loss 0.9851\n",
            "2025-12-03 19:26:57.744529: Pseudo dice [np.float32(0.8937), np.float32(0.5492), np.float32(0.5048), np.float32(0.5475), np.float32(0.5242), np.float32(0.4958), np.float32(0.0008), np.float32(0.3934), np.float32(0.2122), np.float32(0.6241), np.float32(0.6222), np.float32(0.3764), np.float32(0.3535), np.float32(0.0), np.float32(0.0667), np.float32(0.0), np.float32(0.3476), np.float32(0.0051), np.float32(0.3518), np.float32(0.1387), np.float32(0.2233), np.float32(0.0239), np.float32(0.0), np.float32(0.518), np.float32(0.5568), np.float32(0.511), np.float32(0.1371), np.float32(0.052), np.float32(0.0365), np.float32(0.3089), np.float32(0.0107), np.float32(0.1484), np.float32(0.2882), np.float32(0.1975), np.float32(0.0014), np.float32(0.0833), np.float32(0.0), np.float32(0.394), np.float32(0.0), np.float32(0.3227), np.float32(0.0), np.float32(0.494), np.float32(0.5729), np.float32(0.7377), np.float32(0.6287), np.float32(0.0), np.float32(0.0004), np.float32(0.8168)]\n",
            "2025-12-03 19:26:57.747813: Epoch time: 153.39 s\n",
            "2025-12-03 19:26:57.751242: Yayy! New best EMA pseudo Dice: 0.243599995970726\n",
            "2025-12-03 19:26:59.723518: \n",
            "2025-12-03 19:26:59.726615: Epoch 98\n",
            "2025-12-03 19:26:59.730061: Current learning rate: 0.00911\n",
            "2025-12-03 19:29:32.892730: train_loss 0.9766\n",
            "2025-12-03 19:29:32.897220: val_loss 0.9888\n",
            "2025-12-03 19:29:32.902012: Pseudo dice [np.float32(0.8731), np.float32(0.4947), np.float32(0.315), np.float32(0.3853), np.float32(0.3184), np.float32(0.3959), np.float32(0.461), np.float32(0.4633), np.float32(0.1373), np.float32(0.5855), np.float32(0.4431), np.float32(0.3556), np.float32(0.0079), np.float32(0.3489), np.float32(0.0), np.float32(0.0), np.float32(0.1574), np.float32(0.0015), np.float32(0.5417), np.float32(0.1792), np.float32(0.0), np.float32(0.3345), np.float32(0.1329), np.float32(0.4569), np.float32(0.4908), np.float32(0.5465), np.float32(0.0534), np.float32(0.1847), np.float32(0.0742), np.float32(0.3149), np.float32(0.0), np.float32(0.1969), np.float32(0.3442), np.float32(0.0983), np.float32(0.1644), np.float32(0.0035), np.float32(0.0015), np.float32(0.1832), np.float32(0.0), np.float32(0.0499), np.float32(0.0), np.float32(0.3321), np.float32(0.6705), np.float32(0.6734), np.float32(0.7011), np.float32(0.0026), np.float32(0.0), np.float32(0.6517)]\n",
            "2025-12-03 19:29:32.905647: Epoch time: 153.17 s\n",
            "2025-12-03 19:29:32.910095: Yayy! New best EMA pseudo Dice: 0.24660000205039978\n",
            "2025-12-03 19:29:34.946513: \n",
            "2025-12-03 19:29:34.949395: Epoch 99\n",
            "2025-12-03 19:29:34.952455: Current learning rate: 0.0091\n",
            "2025-12-03 19:32:14.507536: train_loss 0.9857\n",
            "2025-12-03 19:32:14.511308: val_loss 0.9839\n",
            "2025-12-03 19:32:14.514750: Pseudo dice [np.float32(0.88), np.float32(0.5539), np.float32(0.5126), np.float32(0.5992), np.float32(0.0129), np.float32(0.2303), np.float32(0.5418), np.float32(0.2152), np.float32(0.0836), np.float32(0.5306), np.float32(0.4842), np.float32(0.3942), np.float32(0.0553), np.float32(0.3353), np.float32(0.0376), np.float32(0.0), np.float32(0.2142), np.float32(0.2241), np.float32(0.4779), np.float32(0.0389), np.float32(0.2365), np.float32(0.0), np.float32(0.5687), np.float32(0.1129), np.float32(0.5366), np.float32(0.4965), np.float32(0.0943), np.float32(0.0153), np.float32(0.0193), np.float32(0.369), np.float32(0.0025), np.float32(0.2181), np.float32(0.0), np.float32(0.5532), np.float32(0.0), np.float32(0.0091), np.float32(0.3137), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0005), np.float32(0.4431), np.float32(0.6423), np.float32(0.6502), np.float32(0.684), np.float32(0.0008), np.float32(0.0057), np.float32(0.727)]\n",
            "2025-12-03 19:32:14.516987: Epoch time: 159.56 s\n",
            "2025-12-03 19:32:15.095080: Yayy! New best EMA pseudo Dice: 0.2493000030517578\n",
            "2025-12-03 19:32:17.118140: \n",
            "2025-12-03 19:32:17.121237: Epoch 100\n",
            "2025-12-03 19:32:17.124644: Current learning rate: 0.0091\n",
            "2025-12-03 19:34:57.103286: train_loss 0.9739\n",
            "2025-12-03 19:34:57.106939: val_loss 0.9902\n",
            "2025-12-03 19:34:57.111294: Pseudo dice [np.float32(0.8485), np.float32(0.3596), np.float32(0.498), np.float32(0.3725), np.float32(0.1543), np.float32(0.5135), np.float32(0.5754), np.float32(0.472), np.float32(0.1331), np.float32(0.7149), np.float32(0.5908), np.float32(0.1724), np.float32(0.3964), np.float32(0.1737), np.float32(0.0), np.float32(0.0), np.float32(0.2846), np.float32(0.252), np.float32(0.3987), np.float32(0.1744), np.float32(0.2526), np.float32(0.0005), np.float32(0.4602), np.float32(0.1081), np.float32(0.3081), np.float32(0.5159), np.float32(0.12), np.float32(0.0568), np.float32(0.0667), np.float32(0.4405), np.float32(0.0), np.float32(0.2844), np.float32(0.2485), np.float32(0.4516), np.float32(0.0), np.float32(0.0), np.float32(0.1422), np.float32(0.0), np.float32(0.0), np.float32(0.0698), np.float32(0.0907), np.float32(0.4442), np.float32(0.5743), np.float32(0.5344), np.float32(0.6294), np.float32(0.0), np.float32(0.0016), np.float32(0.7377)]\n",
            "2025-12-03 19:34:57.114914: Epoch time: 159.99 s\n",
            "2025-12-03 19:34:57.119166: Yayy! New best EMA pseudo Dice: 0.25270000100135803\n",
            "2025-12-03 19:34:59.097756: \n",
            "2025-12-03 19:34:59.101292: Epoch 101\n",
            "2025-12-03 19:34:59.104375: Current learning rate: 0.00909\n",
            "2025-12-03 19:37:37.193077: train_loss 0.9781\n",
            "2025-12-03 19:37:37.197257: val_loss 0.993\n",
            "2025-12-03 19:37:37.201279: Pseudo dice [np.float32(0.85), np.float32(0.5235), np.float32(0.5144), np.float32(0.5584), np.float32(0.2655), np.float32(0.2961), np.float32(0.4553), np.float32(0.3279), np.float32(0.1335), np.float32(0.6321), np.float32(0.637), np.float32(0.501), np.float32(0.3596), np.float32(0.0172), np.float32(0.0723), np.float32(0.0), np.float32(0.3091), np.float32(0.2648), np.float32(0.3294), np.float32(0.0), np.float32(0.0202), np.float32(0.231), np.float32(0.3598), np.float32(0.4839), np.float32(0.321), np.float32(0.4361), np.float32(0.1111), np.float32(0.1059), np.float32(0.2673), np.float32(0.4252), np.float32(0.0481), np.float32(0.2247), np.float32(0.1778), np.float32(0.4514), np.float32(0.0465), np.float32(0.0), np.float32(0.1765), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.4634), np.float32(0.2512), np.float32(0.5428), np.float32(0.6166), np.float32(0.566), np.float32(0.0036), np.float32(0.0009), np.float32(0.7278)]\n",
            "2025-12-03 19:37:37.204502: Epoch time: 158.1 s\n",
            "2025-12-03 19:37:37.219827: Yayy! New best EMA pseudo Dice: 0.25679999589920044\n",
            "2025-12-03 19:37:39.236295: \n",
            "2025-12-03 19:37:39.239799: Epoch 102\n",
            "2025-12-03 19:37:39.243718: Current learning rate: 0.00908\n",
            "2025-12-03 19:40:17.726191: train_loss 0.97\n",
            "2025-12-03 19:40:17.729937: val_loss 0.9722\n",
            "2025-12-03 19:40:17.734722: Pseudo dice [np.float32(0.8671), np.float32(0.5574), np.float32(0.5003), np.float32(0.4976), np.float32(0.4297), np.float32(0.4152), np.float32(0.6244), np.float32(0.4773), np.float32(0.1984), np.float32(0.5286), np.float32(0.6325), np.float32(0.4497), np.float32(0.5043), np.float32(0.0526), np.float32(0.0), np.float32(0.0), np.float32(0.0612), np.float32(0.0917), np.float32(0.5592), np.float32(0.0388), np.float32(0.2504), np.float32(0.1292), np.float32(0.3537), np.float32(0.3435), np.float32(0.4557), np.float32(0.5403), np.float32(0.1616), np.float32(0.0013), np.float32(0.0353), np.float32(0.3701), np.float32(0.0023), np.float32(0.2066), np.float32(0.1602), np.float32(0.5195), np.float32(0.007), np.float32(0.0), np.float32(0.0), np.float32(0.4647), np.float32(0.007), np.float32(0.0), np.float32(0.0), np.float32(0.3649), np.float32(0.5246), np.float32(0.6921), np.float32(0.578), np.float32(0.0), np.float32(0.0543), np.float32(0.7557)]\n",
            "2025-12-03 19:40:17.738785: Epoch time: 158.49 s\n",
            "2025-12-03 19:40:17.755285: Yayy! New best EMA pseudo Dice: 0.2612999975681305\n",
            "2025-12-03 19:40:19.736471: \n",
            "2025-12-03 19:40:19.740226: Epoch 103\n",
            "2025-12-03 19:40:19.744423: Current learning rate: 0.00907\n",
            "2025-12-03 19:42:53.300228: train_loss 0.9747\n",
            "2025-12-03 19:42:53.304006: val_loss 0.9979\n",
            "2025-12-03 19:42:53.307692: Pseudo dice [np.float32(0.8521), np.float32(0.4557), np.float32(0.4366), np.float32(0.6033), np.float32(0.2995), np.float32(0.2812), np.float32(0.5295), np.float32(0.3465), np.float32(0.0486), np.float32(0.729), np.float32(0.636), np.float32(0.4651), np.float32(0.5102), np.float32(0.1409), np.float32(0.0136), np.float32(0.0), np.float32(0.2581), np.float32(0.0), np.float32(0.4724), np.float32(0.2659), np.float32(0.0154), np.float32(0.3171), np.float32(0.2916), np.float32(0.5305), np.float32(0.5046), np.float32(0.422), np.float32(0.1493), np.float32(0.1731), np.float32(0.0), np.float32(0.2783), np.float32(0.0143), np.float32(0.1323), np.float32(0.3943), np.float32(0.3077), np.float32(0.0167), np.float32(0.377), np.float32(0.1735), np.float32(0.0), np.float32(0.0), np.float32(0.2506), np.float32(0.3536), np.float32(0.0527), np.float32(0.6648), np.float32(0.7405), np.float32(0.6524), np.float32(0.0255), np.float32(0.0168), np.float32(0.7263)]\n",
            "2025-12-03 19:42:53.310501: Epoch time: 153.57 s\n",
            "2025-12-03 19:42:53.313366: Yayy! New best EMA pseudo Dice: 0.2662000060081482\n",
            "2025-12-03 19:42:56.223397: \n",
            "2025-12-03 19:42:56.226302: Epoch 104\n",
            "2025-12-03 19:42:56.229486: Current learning rate: 0.00906\n",
            "2025-12-03 19:45:30.067667: train_loss 0.9629\n",
            "2025-12-03 19:45:30.070957: val_loss 0.9818\n",
            "2025-12-03 19:45:30.074096: Pseudo dice [np.float32(0.8849), np.float32(0.5545), np.float32(0.6009), np.float32(0.1719), np.float32(0.1302), np.float32(0.6167), np.float32(0.5173), np.float32(0.2325), np.float32(0.1478), np.float32(0.6592), np.float32(0.4897), np.float32(0.5066), np.float32(0.4654), np.float32(0.3328), np.float32(0.0004), np.float32(0.0), np.float32(0.0003), np.float32(0.0), np.float32(0.4503), np.float32(0.1946), np.float32(0.0199), np.float32(0.4074), np.float32(0.528), np.float32(0.2424), np.float32(0.5092), np.float32(0.5663), np.float32(0.1973), np.float32(0.1227), np.float32(0.2186), np.float32(0.3807), np.float32(0.014), np.float32(0.1928), np.float32(0.0), np.float32(0.5555), np.float32(0.0126), np.float32(0.0988), np.float32(0.0), np.float32(0.187), np.float32(0.2066), np.float32(0.0), np.float32(0.0), np.float32(0.3895), np.float32(0.6649), np.float32(0.7513), np.float32(0.6616), np.float32(0.0003), np.float32(0.0796), np.float32(0.5728)]\n",
            "2025-12-03 19:45:30.076930: Epoch time: 153.85 s\n",
            "2025-12-03 19:45:30.079944: Yayy! New best EMA pseudo Dice: 0.26989999413490295\n",
            "2025-12-03 19:45:32.026268: \n",
            "2025-12-03 19:45:32.028889: Epoch 105\n",
            "2025-12-03 19:45:32.031812: Current learning rate: 0.00905\n",
            "2025-12-03 19:48:07.349254: train_loss 0.9732\n",
            "2025-12-03 19:48:07.365074: val_loss 0.9883\n",
            "2025-12-03 19:48:07.369217: Pseudo dice [np.float32(0.833), np.float32(0.4027), np.float32(0.5339), np.float32(0.4727), np.float32(0.4722), np.float32(0.5368), np.float32(0.4999), np.float32(0.4345), np.float32(0.0957), np.float32(0.4724), np.float32(0.5039), np.float32(0.4228), np.float32(0.1005), np.float32(0.4009), np.float32(0.0), np.float32(0.0), np.float32(0.1805), np.float32(0.0), np.float32(0.4892), np.float32(0.1985), np.float32(0.0722), np.float32(0.2808), np.float32(0.1963), np.float32(0.5663), np.float32(0.4876), np.float32(0.4951), np.float32(0.098), np.float32(0.0693), np.float32(0.2024), np.float32(0.4994), np.float32(0.0519), np.float32(0.2301), np.float32(0.1496), np.float32(0.4084), np.float32(0.1252), np.float32(0.0), np.float32(0.078), np.float32(0.3979), np.float32(0.1342), np.float32(0.0), np.float32(0.2024), np.float32(0.1999), np.float32(0.6728), np.float32(0.6839), np.float32(0.6194), np.float32(0.0123), np.float32(0.0257), np.float32(0.7048)]\n",
            "2025-12-03 19:48:07.372191: Epoch time: 155.32 s\n",
            "2025-12-03 19:48:07.375381: Yayy! New best EMA pseudo Dice: 0.2736000120639801\n",
            "2025-12-03 19:48:09.413649: \n",
            "2025-12-03 19:48:09.416363: Epoch 106\n",
            "2025-12-03 19:48:09.419233: Current learning rate: 0.00904\n",
            "2025-12-03 19:50:48.691801: train_loss 0.9658\n",
            "2025-12-03 19:50:48.695951: val_loss 0.9913\n",
            "2025-12-03 19:50:48.700300: Pseudo dice [np.float32(0.84), np.float32(0.4655), np.float32(0.359), np.float32(0.6156), np.float32(0.2634), np.float32(0.2637), np.float32(0.546), np.float32(0.3495), np.float32(0.1071), np.float32(0.5584), np.float32(0.5152), np.float32(0.4443), np.float32(0.3123), np.float32(0.3166), np.float32(0.0214), np.float32(0.0), np.float32(0.2276), np.float32(0.0), np.float32(0.5275), np.float32(0.1461), np.float32(0.0068), np.float32(0.3294), np.float32(0.4438), np.float32(0.291), np.float32(0.4972), np.float32(0.413), np.float32(0.166), np.float32(0.0065), np.float32(0.0114), np.float32(0.3475), np.float32(0.0012), np.float32(0.3352), np.float32(0.1001), np.float32(0.5602), np.float32(0.0047), np.float32(0.0), np.float32(0.0), np.float32(0.0887), np.float32(0.111), np.float32(0.0), np.float32(0.217), np.float32(0.0003), np.float32(0.6866), np.float32(0.7705), np.float32(0.6348), np.float32(0.0), np.float32(0.0635), np.float32(0.7599)]\n",
            "2025-12-03 19:50:48.703816: Epoch time: 159.28 s\n",
            "2025-12-03 19:50:48.707710: Yayy! New best EMA pseudo Dice: 0.27480000257492065\n",
            "2025-12-03 19:50:50.877813: \n",
            "2025-12-03 19:50:50.895314: Epoch 107\n",
            "2025-12-03 19:50:50.899529: Current learning rate: 0.00903\n",
            "2025-12-03 19:53:25.776100: train_loss 0.9694\n",
            "2025-12-03 19:53:25.779571: val_loss 0.9822\n",
            "2025-12-03 19:53:25.783215: Pseudo dice [np.float32(0.8371), np.float32(0.5519), np.float32(0.5473), np.float32(0.4811), np.float32(0.1435), np.float32(0.4115), np.float32(0.5411), np.float32(0.4313), np.float32(0.0909), np.float32(0.6354), np.float32(0.5459), np.float32(0.4449), np.float32(0.4876), np.float32(0.0665), np.float32(0.0003), np.float32(0.0), np.float32(0.2411), np.float32(0.2435), np.float32(0.4655), np.float32(0.0014), np.float32(0.2464), np.float32(0.016), np.float32(0.3025), np.float32(0.4277), np.float32(0.5266), np.float32(0.5675), np.float32(0.1099), np.float32(0.1283), np.float32(0.0226), np.float32(0.4603), np.float32(0.0042), np.float32(0.3404), np.float32(0.2302), np.float32(0.5226), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.2406), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5035), np.float32(0.6061), np.float32(0.7363), np.float32(0.625), np.float32(0.0), np.float32(0.0252), np.float32(0.6252)]\n",
            "2025-12-03 19:53:25.786138: Epoch time: 154.9 s\n",
            "2025-12-03 19:53:25.789062: Yayy! New best EMA pseudo Dice: 0.2773999869823456\n",
            "2025-12-03 19:53:27.668174: \n",
            "2025-12-03 19:53:27.671047: Epoch 108\n",
            "2025-12-03 19:53:27.674057: Current learning rate: 0.00902\n",
            "2025-12-03 19:56:09.192662: train_loss 0.9701\n",
            "2025-12-03 19:56:09.195879: val_loss 0.9856\n",
            "2025-12-03 19:56:09.203053: Pseudo dice [np.float32(0.867), np.float32(0.5139), np.float32(0.5373), np.float32(0.5234), np.float32(0.2881), np.float32(0.4611), np.float32(0.5055), np.float32(0.3555), np.float32(0.194), np.float32(0.5984), np.float32(0.5124), np.float32(0.2775), np.float32(0.4593), np.float32(0.0004), np.float32(0.0), np.float32(0.0), np.float32(0.0261), np.float32(0.1143), np.float32(0.4913), np.float32(0.0252), np.float32(0.2564), np.float32(0.0026), np.float32(0.2075), np.float32(0.4868), np.float32(0.5809), np.float32(0.5014), np.float32(0.075), np.float32(0.1967), np.float32(0.2587), np.float32(0.3282), np.float32(0.0272), np.float32(0.32), np.float32(0.1228), np.float32(0.541), np.float32(nan), np.float32(0.0455), np.float32(0.0374), np.float32(0.1936), np.float32(0.1148), np.float32(0.0158), np.float32(0.0), np.float32(0.3528), np.float32(0.6404), np.float32(0.7223), np.float32(0.652), np.float32(0.0144), np.float32(0.0208), np.float32(0.8494)]\n",
            "2025-12-03 19:56:09.205914: Epoch time: 161.53 s\n",
            "2025-12-03 19:56:09.208797: Yayy! New best EMA pseudo Dice: 0.2800999879837036\n",
            "2025-12-03 19:56:11.725461: \n",
            "2025-12-03 19:56:11.728281: Epoch 109\n",
            "2025-12-03 19:56:11.731656: Current learning rate: 0.00901\n",
            "2025-12-03 19:58:46.265888: train_loss 0.9685\n",
            "2025-12-03 19:58:46.269277: val_loss 0.9806\n",
            "2025-12-03 19:58:46.272622: Pseudo dice [np.float32(0.877), np.float32(0.5626), np.float32(0.6238), np.float32(0.5195), np.float32(0.3705), np.float32(0.5754), np.float32(0.5079), np.float32(0.3472), np.float32(0.0991), np.float32(0.6451), np.float32(0.4353), np.float32(0.5244), np.float32(0.0004), np.float32(0.3696), np.float32(0.1138), np.float32(0.0), np.float32(0.282), np.float32(0.164), np.float32(0.4047), np.float32(0.0505), np.float32(0.1862), np.float32(0.3318), np.float32(0.3385), np.float32(0.3861), np.float32(0.5457), np.float32(0.4889), np.float32(0.1022), np.float32(0.3119), np.float32(0.0063), np.float32(0.3782), np.float32(0.006), np.float32(0.2574), np.float32(0.2485), np.float32(0.4131), np.float32(0.1806), np.float32(0.0), np.float32(0.248), np.float32(0.0), np.float32(0.3261), np.float32(0.0218), np.float32(0.0665), np.float32(0.4436), np.float32(0.6176), np.float32(0.7692), np.float32(0.6598), np.float32(0.0), np.float32(0.081), np.float32(0.7708)]\n",
            "2025-12-03 19:58:46.275288: Epoch time: 154.54 s\n",
            "2025-12-03 19:58:46.278302: Yayy! New best EMA pseudo Dice: 0.2847000062465668\n",
            "2025-12-03 19:58:48.206846: \n",
            "2025-12-03 19:58:48.209526: Epoch 110\n",
            "2025-12-03 19:58:48.212513: Current learning rate: 0.009\n",
            "2025-12-03 20:01:22.056395: train_loss 0.9627\n",
            "2025-12-03 20:01:22.060382: val_loss 0.9821\n",
            "2025-12-03 20:01:22.065258: Pseudo dice [np.float32(0.8465), np.float32(0.5014), np.float32(0.6037), np.float32(0.3988), np.float32(0.2955), np.float32(0.5921), np.float32(0.5997), np.float32(0.3812), np.float32(0.1574), np.float32(0.6962), np.float32(0.517), np.float32(0.4487), np.float32(0.4551), np.float32(0.1332), np.float32(0.2087), np.float32(0.0), np.float32(0.2412), np.float32(0.2412), np.float32(0.4752), np.float32(0.1684), np.float32(0.1946), np.float32(0.0), np.float32(0.3334), np.float32(0.3676), np.float32(0.4941), np.float32(0.5425), np.float32(0.1573), np.float32(0.13), np.float32(0.0057), np.float32(0.2882), np.float32(0.0672), np.float32(0.3529), np.float32(0.2759), np.float32(0.2328), np.float32(0.3533), np.float32(0.0), np.float32(0.1635), np.float32(0.2295), np.float32(0.4311), np.float32(0.0068), np.float32(0.1494), np.float32(0.4097), np.float32(0.506), np.float32(0.6155), np.float32(0.6308), np.float32(0.0), np.float32(0.0558), np.float32(0.7703)]\n",
            "2025-12-03 20:01:22.068586: Epoch time: 153.85 s\n",
            "2025-12-03 20:01:22.072395: Yayy! New best EMA pseudo Dice: 0.289000004529953\n",
            "2025-12-03 20:01:24.842269: \n",
            "2025-12-03 20:01:24.845639: Epoch 111\n",
            "2025-12-03 20:01:24.848855: Current learning rate: 0.009\n",
            "2025-12-03 20:04:04.077719: train_loss 0.9732\n",
            "2025-12-03 20:04:04.081393: val_loss 0.9731\n",
            "2025-12-03 20:04:04.084470: Pseudo dice [np.float32(0.8685), np.float32(0.6137), np.float32(0.5787), np.float32(0.6682), np.float32(0.4831), np.float32(0.4976), np.float32(0.5638), np.float32(0.379), np.float32(0.3834), np.float32(0.6937), np.float32(0.6692), np.float32(0.5874), np.float32(0.4319), np.float32(0.2256), np.float32(0.0943), np.float32(0.0), np.float32(0.2466), np.float32(0.3198), np.float32(0.4855), np.float32(0.0056), np.float32(0.0836), np.float32(0.3297), np.float32(0.4748), np.float32(0.4079), np.float32(0.5435), np.float32(0.444), np.float32(0.1906), np.float32(0.0875), np.float32(0.1154), np.float32(0.3793), np.float32(0.0219), np.float32(0.4011), np.float32(0.304), np.float32(0.474), np.float32(0.2189), np.float32(0.0), np.float32(0.0771), np.float32(0.2762), np.float32(0.4201), np.float32(0.0), np.float32(0.4942), np.float32(0.0163), np.float32(0.6698), np.float32(0.7126), np.float32(0.6318), np.float32(0.0056), np.float32(0.0409), np.float32(0.2884)]\n",
            "2025-12-03 20:04:04.087689: Epoch time: 159.24 s\n",
            "2025-12-03 20:04:04.091125: Yayy! New best EMA pseudo Dice: 0.2953000068664551\n",
            "2025-12-03 20:04:06.050726: \n",
            "2025-12-03 20:04:06.053767: Epoch 112\n",
            "2025-12-03 20:04:06.056236: Current learning rate: 0.00899\n",
            "2025-12-03 20:06:41.795616: train_loss 0.967\n",
            "2025-12-03 20:06:41.798799: val_loss 0.9879\n",
            "2025-12-03 20:06:41.802100: Pseudo dice [np.float32(0.8662), np.float32(0.4961), np.float32(0.4224), np.float32(0.4986), np.float32(0.468), np.float32(0.4183), np.float32(0.2027), np.float32(0.2612), np.float32(0.2834), np.float32(0.5019), np.float32(0.597), np.float32(0.4405), np.float32(0.4126), np.float32(0.0883), np.float32(0.2229), np.float32(0.0), np.float32(0.0878), np.float32(0.2403), np.float32(0.3961), np.float32(0.1478), np.float32(0.2449), np.float32(0.0), np.float32(0.3031), np.float32(0.5849), np.float32(0.4351), np.float32(0.4357), np.float32(0.1465), np.float32(0.0944), np.float32(0.0027), np.float32(0.4741), np.float32(0.0292), np.float32(0.3231), np.float32(0.2764), np.float32(0.2775), np.float32(0.0), np.float32(0.5675), np.float32(0.0), np.float32(0.2773), np.float32(0.0574), np.float32(0.1259), np.float32(0.0), np.float32(0.5029), np.float32(0.5634), np.float32(0.6961), np.float32(0.6929), np.float32(0.0097), np.float32(0.0253), np.float32(0.7569)]\n",
            "2025-12-03 20:06:41.804760: Epoch time: 155.75 s\n",
            "2025-12-03 20:06:41.807869: Yayy! New best EMA pseudo Dice: 0.296999990940094\n",
            "2025-12-03 20:06:43.726614: \n",
            "2025-12-03 20:06:44.335739: Epoch 113\n",
            "2025-12-03 20:06:44.339286: Current learning rate: 0.00898\n",
            "2025-12-03 20:09:19.653845: train_loss 0.9647\n",
            "2025-12-03 20:09:19.657948: val_loss 0.9909\n",
            "2025-12-03 20:09:19.661414: Pseudo dice [np.float32(0.8753), np.float32(0.4739), np.float32(0.5627), np.float32(0.4332), np.float32(0.2462), np.float32(0.4818), np.float32(0.4535), np.float32(0.2151), np.float32(0.1915), np.float32(0.4326), np.float32(0.4148), np.float32(0.3464), np.float32(0.3416), np.float32(0.2891), np.float32(0.3297), np.float32(0.0), np.float32(0.2219), np.float32(0.0009), np.float32(0.5207), np.float32(0.2349), np.float32(0.0314), np.float32(0.2904), np.float32(0.115), np.float32(0.5651), np.float32(0.3385), np.float32(0.4829), np.float32(0.1692), np.float32(0.3168), np.float32(0.3029), np.float32(0.3348), np.float32(0.1499), np.float32(0.3653), np.float32(0.2194), np.float32(0.4857), np.float32(0.0), np.float32(0.1475), np.float32(0.253), np.float32(0.2714), np.float32(0.2491), np.float32(0.0063), np.float32(0.1637), np.float32(0.3202), np.float32(0.5503), np.float32(0.6972), np.float32(0.6542), np.float32(0.0019), np.float32(0.0784), np.float32(0.6557)]\n",
            "2025-12-03 20:09:19.665038: Epoch time: 155.93 s\n",
            "2025-12-03 20:09:19.667895: Yayy! New best EMA pseudo Dice: 0.29910001158714294\n",
            "2025-12-03 20:09:21.560865: \n",
            "2025-12-03 20:09:21.564304: Epoch 114\n",
            "2025-12-03 20:09:21.568421: Current learning rate: 0.00897\n",
            "2025-12-03 20:11:56.902383: train_loss 0.9627\n",
            "2025-12-03 20:11:56.906651: val_loss 0.9943\n",
            "2025-12-03 20:11:56.911395: Pseudo dice [np.float32(0.8893), np.float32(0.41), np.float32(0.4485), np.float32(0.5396), np.float32(0.1597), np.float32(0.4086), np.float32(0.598), np.float32(0.2572), np.float32(0.2077), np.float32(0.4714), np.float32(0.475), np.float32(0.3352), np.float32(0.2544), np.float32(0.3204), np.float32(0.0257), np.float32(0.0), np.float32(0.1203), np.float32(0.1982), np.float32(0.5991), np.float32(0.1467), np.float32(0.134), np.float32(0.2237), np.float32(0.2206), np.float32(0.5249), np.float32(0.4327), np.float32(0.5093), np.float32(0.1155), np.float32(0.4298), np.float32(0.0053), np.float32(0.3836), np.float32(0.1764), np.float32(0.278), np.float32(0.2086), np.float32(0.4022), np.float32(0.1173), np.float32(0.0), np.float32(0.4088), np.float32(0.0), np.float32(0.0204), np.float32(0.0325), np.float32(0.0294), np.float32(0.4315), np.float32(0.549), np.float32(0.6588), np.float32(0.6491), np.float32(0.0657), np.float32(0.0245), np.float32(0.7023)]\n",
            "2025-12-03 20:11:56.927099: Epoch time: 155.34 s\n",
            "2025-12-03 20:11:56.931022: Yayy! New best EMA pseudo Dice: 0.2996000051498413\n",
            "2025-12-03 20:11:59.042656: \n",
            "2025-12-03 20:11:59.045510: Epoch 115\n",
            "2025-12-03 20:11:59.048578: Current learning rate: 0.00896\n",
            "2025-12-03 20:14:33.407102: train_loss 0.9627\n",
            "2025-12-03 20:14:33.426144: val_loss 0.9862\n",
            "2025-12-03 20:14:33.430586: Pseudo dice [np.float32(0.8248), np.float32(0.6091), np.float32(0.5719), np.float32(0.4739), np.float32(0.4413), np.float32(0.626), np.float32(0.4237), np.float32(0.4963), np.float32(0.5559), np.float32(0.6955), np.float32(0.5615), np.float32(0.4926), np.float32(0.4437), np.float32(0.2239), np.float32(0.1364), np.float32(0.0), np.float32(0.2749), np.float32(0.2574), np.float32(0.4887), np.float32(0.1255), np.float32(0.1018), np.float32(0.3602), np.float32(0.2338), np.float32(0.5511), np.float32(0.44), np.float32(0.57), np.float32(0.1674), np.float32(0.2094), np.float32(0.0956), np.float32(0.4248), np.float32(0.0614), np.float32(0.4229), np.float32(0.2983), np.float32(0.4132), np.float32(0.0), np.float32(0.4661), np.float32(0.2093), np.float32(0.0), np.float32(0.0518), np.float32(0.0011), np.float32(0.4299), np.float32(0.0), np.float32(0.5778), np.float32(0.7252), np.float32(0.6368), np.float32(0.0009), np.float32(0.047), np.float32(0.7068)]\n",
            "2025-12-03 20:14:33.434319: Epoch time: 154.37 s\n",
            "2025-12-03 20:14:33.439061: Yayy! New best EMA pseudo Dice: 0.30489999055862427\n",
            "2025-12-03 20:14:35.981039: \n",
            "2025-12-03 20:14:35.984542: Epoch 116\n",
            "2025-12-03 20:14:35.988679: Current learning rate: 0.00895\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n",
            "    sys.exit(run_training_entry())\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nnUNet/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n",
            "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
            "  File \"/content/nnUNet/nnunetv2/run/run_training.py\", line 207, in run_training\n",
            "    nnunet_trainer.run_training()\n",
            "  File \"/content/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1371, in run_training\n",
            "  File \"/content/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 991, in train_step\n",
            "    l = self.loss(output, target)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nnUNet/nnunetv2/training/loss/deep_supervision.py\", line 29, in forward\n",
            "    return sum([weights[i] * self.loss(*inputs) for i, inputs in enumerate(zip(*args)) if weights[i] != 0.0])\n",
            "                             ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nnUNet/nnunetv2/training/loss/dice_ce_cldice_loss.py\", line 74, in forward\n",
            "    cldice = soft_cldice_loss_3d(pred_fg, target_fg, iter_=self.iter_, smooth=self.smooth)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nnUNet/nnunetv2/training/loss/dice_ce_cldice_loss.py\", line 34, in soft_cldice_loss_3d\n",
            "    SkelL = _soft_skel3d(target_fg, iter_=iter_)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nnUNet/nnunetv2/training/loss/dice_ce_cldice_loss.py\", line 17, in _soft_skel3d\n",
            "    xp = x.clone()\n",
            "         ^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Training fold 0\n",
        "!nnUNetv2_train 000 3d_fullres 0 -tr nnUNetTrainerDiceCEClDiceLoss -device cuda -pretrained_weights /content/drive/MyDrive/Projets_perso/Projet_IA/TopBrain2025_nnunet/nnunet_data/nnUNet_results/Dataset100_CTA_AND_MRA_pretraining/nnUNetTrainerDiceCEClDiceLoss__nnUNetPlans_From_000__3d_fullres/fold_all/checkpoint_best.pth"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}